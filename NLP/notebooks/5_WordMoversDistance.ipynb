{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hello again, welcome to notebook 5!\n",
    "\n",
    "In this notebook we will look at:\n",
    "\n",
    "* Measuring the distances between sentences using the Word Mover's Distance\n",
    "* Comparing different distance metrics for sentences.\n",
    "\n",
    "It is recommended that you complete all exercises that are not marked as optional.\n",
    "\n",
    "Feel free to be creative and write your own code wherever you want!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "[nltk_data] Downloading package stopwords to\n[nltk_data]     C:\\Users\\ollie\\AppData\\Roaming\\nltk_data...\n[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import string\n",
    "import os\n",
    "\n",
    "from nltk import download\n",
    "download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "import gensim.downloader as api\n",
    "from gensim.models.keyedvectors import Word2VecKeyedVectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will need to preprocess our sentences using some of the functions from the ```PreparingTextData``` notebook. Let's copy these here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = stopwords.words('english')\n",
    "\n",
    "def basic_tokenizer(sentence):\n",
    "    out = sentence\n",
    "    for x in string.punctuation:\n",
    "        out = out.replace(x, '')\n",
    "    out = out.lower().split()\n",
    "    return out\n",
    "\n",
    "def remove_stopwords(sentence, stop_words):\n",
    "    return [word for word in sentence if word not in stop_words]\n",
    "\n",
    "def preprocess(sentence, stop_words):\n",
    "    clean_sentence = remove_stopwords(basic_tokenizer(sentence), stop_words)\n",
    "    return clean_sentence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will also need the Word2Vec vectors that we downloaded in the ```CosineSimilarity``` notebook. We will normalise the vectors as we did before to speed up any similarity calculations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Word2VecKeyedVectors.load(\"./models/word2vec.model\")\n",
    "model.init_sims(replace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lesson 1: Word Mover's Distance\n",
    "\n",
    "The Word Mover's Distance (WMD) is a measure of the 'distance' between two text documents (or sentences).\n",
    "\n",
    "<img src=\"images/wmd_intuition.png\" width=\"600\">\n",
    "\n",
    "All non-stopwords (**bold**) of both sentences are embedded in a word2vec space. The distance between the two sentences is the minimum cumulative distance that the words in the first sentence must travel to exactly match those in the second.\n",
    "\n",
    "The image below shows how the WMD is calculated for two different cases:\n",
    "\n",
    "<img src=\"images/wmd_calculation.png\" width=\"500\">\n",
    "\n",
    "In the top example, we have two sentences, $D_1$ and $D_2$ that have no non-stopwords in common with a third sentences $D_0$. The arrows represent the flow between two words (this is a technical term but is really just 'which word moves where') and are labelled by their contribution to the overall distance. Notice that $D_1$ is closer to $D_0$ than $D_2$. This is what we'd expect!\n",
    "\n",
    "On the bottom, we have two sentences with different numbers of words. This results in words from $D_3$ being moved to multiple similar words.\n",
    "\n",
    "(**Source**: http://proceedings.mlr.press/v37/kusnerb15.pdf)\n",
    "\n",
    "The maths behind the WMD is pretty complicated, but hopefully this high level description should give you a good idea of what it's measuring! Rather than implementing it ourselves, we will use the ```.wmdistance()``` function in Python's ```gensim``` library.\n",
    "\n",
    "Let's start by preprocessing the sentences from the example above:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "The president greets the press in Chicago ['president', 'greets', 'press', 'chicago']\nObama speaks to the media in Illinois ['obama', 'speaks', 'media', 'illinois']\nThe band gave a concert in Japan ['band', 'gave', 'concert', 'japan']\nObama speaks in Illinois ['obama', 'speaks', 'illinois']\n"
     ]
    }
   ],
   "source": [
    "D0 = 'The president greets the press in Chicago'\n",
    "D1 = 'Obama speaks to the media in Illinois'\n",
    "D2 = 'The band gave a concert in Japan'\n",
    "D3 = 'Obama speaks in Illinois'\n",
    "\n",
    "D0_preprocessed = preprocess(D0, stop_words)\n",
    "D1_preprocessed = preprocess(D1, stop_words)\n",
    "D2_preprocessed = preprocess(D2, stop_words)\n",
    "D3_preprocessed = preprocess(D3, stop_words)\n",
    "\n",
    "print(D0, D0_preprocessed)\n",
    "print(D1, D1_preprocessed)\n",
    "print(D2, D2_preprocessed)\n",
    "print(D3, D3_preprocessed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now calculating the WMD is really easy! Remember that ```model``` is our Word2Vec model from above, and note that the preprocessed sentences ```D0``` and ```D1``` should be fed into ```.wmdistance()``` rather than the sentences themselves."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "The president greets the press in Chicago\nObama speaks to the media in Illinois\nWMD: 1.0175\n******************************************\nThe president greets the press in Chicago\nThe band gave a concert in Japan\nWMD: 1.2700\n******************************************\nThe president greets the press in Chicago\nObama speaks in Illinois\nWMD: 1.1221\n******************************************\n"
     ]
    }
   ],
   "source": [
    "for D, D_prep in zip([D1, D2, D3], [D1_preprocessed, D2_preprocessed, D3_preprocessed]):\n",
    "    wmd = model.wmdistance(D0_preprocessed, D_prep)\n",
    "    print(D0)\n",
    "    print(D)\n",
    "    print(f'WMD: {wmd:.4f}')\n",
    "    print('*' * 42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1: WMD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q1.1 - The WMD values calculated for the pairs of sentences here are different to those in the\n",
    "#      - picture above. Why might that be? different word2vec model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0.0\n"
     ]
    }
   ],
   "source": [
    "# Q1.2 - What's the WMD between two identical sentences?\n",
    "\n",
    "first_sentence = \"hello there, general kenboi\"\n",
    "sentence = preprocess(first_sentence, stop_words)\n",
    "wmd = model.wmdistance(sentence, sentence)\n",
    "print(wmd)\n",
    "# TODO: Call the WMD on your preprocessed `first_sentence` with itself"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "1.1736532357763267\n"
     ]
    }
   ],
   "source": [
    "# Q1.3 - What's the maximum (finite) WMD that you can find?\n",
    "#      - What can you say about the bounds of WMD compared to other distance metrics?\n",
    "\n",
    "second_sentence = \"goodbye darth vader\"\n",
    "sentence2 = preprocess(second_sentence, stop_words)\n",
    "wmd = model.wmdistance(sentence, sentence2)\n",
    "print(wmd)\n",
    "# TODO: Call the WMD on your preprocessed sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lesson 2: Comparing distance metrics\n",
    "\n",
    "Let's compare the Word Mover's Distance for various sentences to the Jaccard Distance that we calculated in the first notebook. Remember that in order to calculate the Jaccard Distance, we'll need to come up with a Bag of Words representation for our sentences.\n",
    "\n",
    "The function below calculates a BoW representation and vocabulary for a list of preprocessed sentences, e.g.\n",
    "\n",
    "```[['obama', 'speaks', 'media', 'illinois'], ['president', 'greets', 'press', 'chicago']]```.\n",
    "\n",
    "This is slightly different to the function that we saw in the JaccardDistance notebook which took a list of strings (un-tokenized sentences) as input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bow_and_vocab(sentences):\n",
    "    vocab = list(set(sentences[0]).union(*sentences[1:]))\n",
    "    bow = [[s.count(word) for word in vocab] for s in sentences]\n",
    "    return bow, vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "bow, vocab = get_bow_and_vocab([D0_preprocessed, D1_preprocessed])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can use the ```calculate_jaccard_dist``` function from the ```JaccardDistance``` notebook to calculate the Jaccard distance between our two sentences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_jaccard_dist(u, v):\n",
    "    intersection = 0\n",
    "    union = 0\n",
    "    for i in range(len(u)):\n",
    "        \n",
    "        # The word is present in both vectors\n",
    "        if u[i] > 0 and v[i] > 0:\n",
    "            intersection += 1\n",
    "            \n",
    "        # The word is present in one of the vectors\n",
    "        if u[i] > 0 or v[i] > 0:\n",
    "            union += 1\n",
    "            \n",
    "    jaccard_dist = 1 - (intersection / union)\n",
    "    return jaccard_dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "The president greets the press in Chicago\nObama speaks to the media in Illinois\nJaccard distance: 1.0000\n"
     ]
    }
   ],
   "source": [
    "# Jaccard distance between s1 and s2\n",
    "jaccard = calculate_jaccard_dist(bow[0], bow[1])\n",
    "print(D0)\n",
    "print(D1)\n",
    "print(f'Jaccard distance: {jaccard:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2: Comparing distance metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q2.1 - What do you notice about the Jaccard distance compared to the WMD between sentences D0 and D1?\n",
    "#      - (HINT: Remember to think about the maximum and minimum values of each metric in your answer.)\n",
    "# Q2.2 - Which metric would you say is more realistic, and why?\n",
    "#      - (HINT: How does each metric handle synonyms?)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lesson 3: Earth Mover's Distance\n",
    "So far in this notebook, we've made use of the `gensim` library's `.wmdistance()` to calculate the WMD between sentences. In this lesson, we'll implement the Earth Mover's Distance (EMD) - a generalisation of the WMD - from scratch.\n",
    "\n",
    "To calculate the EMD, we'll need to do the following:\n",
    "* Represent each document (or sentence) as a list of word vectors. Call these lists $u$ and $v$, and suppose that $u$ has length $m$ and $v$ has length $n$.\n",
    "* For each pair of vectors $(u_i, v_j)$ where $u_i$ is a vector from $u$ and $v_j$ is a vector from $v$, calculate the Euclidean distance $d_{i,j} = ||u_i - v_j||$. Let this value be the $(i, j)^{th}$ entry in a distance matrix $D$ (an $m \\times n$ matrix).\n",
    "* Find the set of $\\min(m, n)$ pairs of words that minimises the total distance between the two documents.\n",
    "* Calculate the EMD to be the mean of the distances between pairs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example\n",
    "Suppose that the words 'shop', 'apple', 'pear' and 'supermarket' have the following vector representations:\n",
    "* 'shop' = $(1, 2)$\n",
    "* 'apple' = $(5, 7)$\n",
    "* 'pear' = $(5, 6)$\n",
    "* 'supermarket' = $(2, 3)$\n",
    "\n",
    "Then the sentence 'shop apple' is represented by the list $u = [(1, 2), (5, 7)]$ and the sentence 'pear supermarket' by $v = [(5, 6), (2, 3)]$. The distance matrix $D$ is given by\n",
    "\n",
    "$\n",
    "D = \\begin{pmatrix}\n",
    "\\sqrt{32} & \\sqrt{2}\\\\\n",
    "1 & 5\\\\\n",
    "\\end{pmatrix}\n",
    "$\n",
    "\n",
    "since:\n",
    "* $||(1,2) - (5,6)|| = \\sqrt{32}$,\n",
    "* $||(1,2) - (2,3)|| = \\sqrt{2}$,\n",
    "\n",
    "and so on.\n",
    "\n",
    "Now we have two possible pairings of vectors:\n",
    "* $((1,2),(5,6))$ and $((5,7),(2,3))$ with total distance $\\sqrt{32} + 5$, or\n",
    "* $((1,2),(2,3))$ and $((5,7),(5,6))$ with total distance $\\sqrt{2} + 1$, or\n",
    "\n",
    "Since $\\sqrt{2} + 1 < \\sqrt(32) + 5$, we take the second pairing. Thus our sentences 'shop apple' and 'pear supermarket' have an EMD of $\\frac{1 + \\sqrt{2}}{2}$ where the pairs are ('shop', 'supermarket') and ('apple', 'pear')."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3: EMD\n",
    "Now that we've seen an example of the EMD in action, let's code it up! The hardest part of the EMD calculation is finding the pairs of vectors that minimise the total distance to move. For sentences of only two words it's easy, but as our sentences grow longer it will become much harder! Thankfully there's a Python module `lapsolver` which will be able to do this calculation for us."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lapsolver import solve_dense"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll isolate the distance matrix calculation from the main EMD function to make things clearer. Have a look at the `calculate_dist_matrix` function below and check that you understand what it's doing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_dist_matrix(u, v):\n",
    "    mat = np.zeros(shape=(len(u), len(v)), dtype=np.float32)\n",
    "    for i in range(len(u)):\n",
    "        for j in range(len(v)):\n",
    "            mat[i, j] = np.linalg.norm(u[i] - v[j])\n",
    "    return mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q3.1 - Complete the `calculate_emd_and_pairs` function below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_emd_and_pairs(s1, s2, model, stop_words):    \n",
    "    # TO DO: preprocess the sentences\n",
    "    clean_s1 =\n",
    "    clean_s2 =\n",
    "\n",
    "    # Apply Word2Vec to the sentences\n",
    "    s1_vec = [model[w] for w in clean_s1]\n",
    "    s2_vec = [model[w] for w in clean_s2]\n",
    "    \n",
    "    # TO DO: calculate the distances between all the word vectors\n",
    "    dist_matrix =\n",
    "    \n",
    "    # Pair the word vectors together\n",
    "    assignment = solve_dense(dist_matrix)\n",
    "    pairs = [(clean_s1[i], clean_s2[j]) for i, j in zip(assignment[0], assignment[1])]\n",
    "    \n",
    "    # TO DO: take the mean of the distances between pairs\n",
    "    # HINT: what happens if you index into `dist_matrix` using `assignment`?\n",
    "    emd =\n",
    "    \n",
    "    return emd, pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q3.2 - Check that your function works by running the cell below.\n",
    "#      - Compare the EMD values calculated between (D0, D1), (D0, D2) and (D0, D3) to those calculated\n",
    "#      - using the `gensim` implementation in Lesson 1.\n",
    "#      - Are they the same or different? Can you think why this might be?\n",
    "\n",
    "# Q3.3 - Look at the pairs produced when calculating the EMD between D0 and D3.\n",
    "#      - Why might our EMD implementation be less accurate than the gensim WMD one in this case?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The EMD between \"The president greets the press in Chicago\" and \"Obama speaks to the media in Illinois\" is 1.0175\n",
      "The pairs are: [('president', 'obama'), ('greets', 'speaks'), ('press', 'media'), ('chicago', 'illinois')]\n",
      "*******************************************************************************************************************\n",
      "The EMD between \"The president greets the press in Chicago\" and \"The band gave a concert in Japan\" is 1.2700\n",
      "The pairs are: [('president', 'band'), ('greets', 'gave'), ('press', 'concert'), ('chicago', 'japan')]\n",
      "*******************************************************************************************************************\n",
      "The EMD between \"The president greets the press in Chicago\" and \"Obama speaks in Illinois\" is 1.0590\n",
      "The pairs are: [('president', 'obama'), ('greets', 'speaks'), ('chicago', 'illinois')]\n",
      "*******************************************************************************************************************\n"
     ]
    }
   ],
   "source": [
    "for D in [D1, D2, D3]:\n",
    "    emd, pairs = calculate_emd_and_pairs(D0, D, model, stop_words)\n",
    "\n",
    "    print(f'The EMD between \"{D0}\" and \"{D}\" is {emd:.4f}')\n",
    "    print(f'The pairs are: {pairs}')\n",
    "    print('*' * 115)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}