{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hey there, welcome to your final challenge\n",
    "\n",
    "You're finally going to have a chance to apply the skills you've been learning on a real-life dataset.\n",
    "\n",
    "Your task is to predict if a given news headline is sarcastic or not.\n",
    "\n",
    "<img src=\"images/you_dont_say.jpg\" width=\"400\">\n",
    "\n",
    "--- \n",
    "\n",
    "A good way to think about how a machine might detect sarcasm is to try it yourself.\n",
    "Which of these headlines is sarcastic?\n",
    "\n",
    "* \"Thinking about the way you look all the time burns 5,000 calories an hour\"\n",
    "* \"Safeguarding the well-being of children\"\n",
    "\n",
    "How did you make your decision? Which features of the text gave it away?\n",
    "This is the thought process you will need to make a good model.\n",
    "\n",
    "--- \n",
    "\n",
    "Feel free to be creative and write your own code wherever you want!\n",
    "\n",
    "The provided functions are only there to help you if you get stuck :)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'gensim'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-6f49f460295a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear_model\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mLogisticRegression\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_selection\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mgensim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeyedvectors\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mWord2VecKeyedVectors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcorpus\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mstopwords\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mstring\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'gensim'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from gensim.models.keyedvectors import Word2VecKeyedVectors\n",
    "from nltk.corpus import stopwords\n",
    "import string"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of data: 15862\n",
      "Sarcasm percentage: 43%\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article_link</th>\n",
       "      <th>headline</th>\n",
       "      <th>is_sarcastic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://www.huffingtonpost.com/entry/versace-b...</td>\n",
       "      <td>former versace store clerk sues over secret 'b...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://www.huffingtonpost.com/entry/roseanne-...</td>\n",
       "      <td>the 'roseanne' revival catches up to our thorn...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://local.theonion.com/mom-starting-to-fea...</td>\n",
       "      <td>mom starting to fear son's web series closest ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://politics.theonion.com/boehner-just-wan...</td>\n",
       "      <td>boehner just wants wife to listen, not come up...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://www.huffingtonpost.com/entry/jk-rowlin...</td>\n",
       "      <td>j.k. rowling wishes snape happy birthday in th...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        article_link  \\\n",
       "0  https://www.huffingtonpost.com/entry/versace-b...   \n",
       "1  https://www.huffingtonpost.com/entry/roseanne-...   \n",
       "2  https://local.theonion.com/mom-starting-to-fea...   \n",
       "3  https://politics.theonion.com/boehner-just-wan...   \n",
       "4  https://www.huffingtonpost.com/entry/jk-rowlin...   \n",
       "\n",
       "                                            headline  is_sarcastic  \n",
       "0  former versace store clerk sues over secret 'b...             0  \n",
       "1  the 'roseanne' revival catches up to our thorn...             0  \n",
       "2  mom starting to fear son's web series closest ...             1  \n",
       "3  boehner just wants wife to listen, not come up...             1  \n",
       "4  j.k. rowling wishes snape happy birthday in th...             0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the in the data from CSV\n",
    "fp = '../data/train_df.csv'\n",
    "df = pd.read_csv(fp)\n",
    "\n",
    "# Print the number of headlines that we're dealing with\n",
    "print(f'Size of data: {len(df)}')\n",
    "\n",
    "# Print the percentage of headlines that are sarcastic\n",
    "sarcasm_percentage = int(100 * sum(df['is_sarcastic']) / len(df))\n",
    "print(f'Sarcasm percentage: {sarcasm_percentage}%')\n",
    "\n",
    "# Show a sample of the data\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article_link</th>\n",
       "      <th>headline</th>\n",
       "      <th>is_sarcastic</th>\n",
       "      <th>clean_head</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://www.huffingtonpost.com/entry/versace-b...</td>\n",
       "      <td>former versace store clerk sues over secret 'b...</td>\n",
       "      <td>0</td>\n",
       "      <td>[former, versace, store, clerk, sues, secret, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://www.huffingtonpost.com/entry/roseanne-...</td>\n",
       "      <td>the 'roseanne' revival catches up to our thorn...</td>\n",
       "      <td>0</td>\n",
       "      <td>[roseanne, revival, catches, thorny, political...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://local.theonion.com/mom-starting-to-fea...</td>\n",
       "      <td>mom starting to fear son's web series closest ...</td>\n",
       "      <td>1</td>\n",
       "      <td>[mom, starting, fear, sons, web, series, close...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://politics.theonion.com/boehner-just-wan...</td>\n",
       "      <td>boehner just wants wife to listen, not come up...</td>\n",
       "      <td>1</td>\n",
       "      <td>[boehner, wants, wife, listen, come, alternati...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://www.huffingtonpost.com/entry/jk-rowlin...</td>\n",
       "      <td>j.k. rowling wishes snape happy birthday in th...</td>\n",
       "      <td>0</td>\n",
       "      <td>[jk, rowling, wishes, snape, happy, birthday, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        article_link  \\\n",
       "0  https://www.huffingtonpost.com/entry/versace-b...   \n",
       "1  https://www.huffingtonpost.com/entry/roseanne-...   \n",
       "2  https://local.theonion.com/mom-starting-to-fea...   \n",
       "3  https://politics.theonion.com/boehner-just-wan...   \n",
       "4  https://www.huffingtonpost.com/entry/jk-rowlin...   \n",
       "\n",
       "                                            headline  is_sarcastic  \\\n",
       "0  former versace store clerk sues over secret 'b...             0   \n",
       "1  the 'roseanne' revival catches up to our thorn...             0   \n",
       "2  mom starting to fear son's web series closest ...             1   \n",
       "3  boehner just wants wife to listen, not come up...             1   \n",
       "4  j.k. rowling wishes snape happy birthday in th...             0   \n",
       "\n",
       "                                          clean_head  \n",
       "0  [former, versace, store, clerk, sues, secret, ...  \n",
       "1  [roseanne, revival, catches, thorny, political...  \n",
       "2  [mom, starting, fear, sons, web, series, close...  \n",
       "3  [boehner, wants, wife, listen, come, alternati...  \n",
       "4  [jk, rowling, wishes, snape, happy, birthday, ...  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stop_words = stopwords.words('english')\n",
    "\n",
    "def basic_tokenizer(sentence):\n",
    "    out = sentence\n",
    "    for x in string.punctuation:\n",
    "        out = out.replace(x, '')\n",
    "    out = out.lower().split()\n",
    "    return out\n",
    "\n",
    "def remove_stopwords(sentence, stop_words):\n",
    "    return [word for word in sentence if word not in stop_words]\n",
    "\n",
    "def preprocess(sentence, stop_words):\n",
    "    clean_sentence = remove_stopwords(basic_tokenizer(sentence), stop_words)\n",
    "    return clean_sentence\n",
    "\n",
    "df['clean_head'] = df['headline'].apply(lambda x: preprocess(x, stop_words))\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Features\n",
    "\n",
    "The first step we have to take in a machine learning task is to create features.\n",
    "\n",
    "Below our features will be the counts of each word in the vocab in each sentence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article_link</th>\n",
       "      <th>headline</th>\n",
       "      <th>is_sarcastic</th>\n",
       "      <th>clean_head</th>\n",
       "      <th>bow</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://www.huffingtonpost.com/entry/versace-b...</td>\n",
       "      <td>former versace store clerk sues over secret 'b...</td>\n",
       "      <td>0</td>\n",
       "      <td>[former, versace, store, clerk, sues, secret, ...</td>\n",
       "      <td>[0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://www.huffingtonpost.com/entry/roseanne-...</td>\n",
       "      <td>the 'roseanne' revival catches up to our thorn...</td>\n",
       "      <td>0</td>\n",
       "      <td>[roseanne, revival, catches, thorny, political...</td>\n",
       "      <td>[0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://local.theonion.com/mom-starting-to-fea...</td>\n",
       "      <td>mom starting to fear son's web series closest ...</td>\n",
       "      <td>1</td>\n",
       "      <td>[mom, starting, fear, sons, web, series, close...</td>\n",
       "      <td>[0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://politics.theonion.com/boehner-just-wan...</td>\n",
       "      <td>boehner just wants wife to listen, not come up...</td>\n",
       "      <td>1</td>\n",
       "      <td>[boehner, wants, wife, listen, come, alternati...</td>\n",
       "      <td>[0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://www.huffingtonpost.com/entry/jk-rowlin...</td>\n",
       "      <td>j.k. rowling wishes snape happy birthday in th...</td>\n",
       "      <td>0</td>\n",
       "      <td>[jk, rowling, wishes, snape, happy, birthday, ...</td>\n",
       "      <td>[0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        article_link  \\\n",
       "0  https://www.huffingtonpost.com/entry/versace-b...   \n",
       "1  https://www.huffingtonpost.com/entry/roseanne-...   \n",
       "2  https://local.theonion.com/mom-starting-to-fea...   \n",
       "3  https://politics.theonion.com/boehner-just-wan...   \n",
       "4  https://www.huffingtonpost.com/entry/jk-rowlin...   \n",
       "\n",
       "                                            headline  is_sarcastic  \\\n",
       "0  former versace store clerk sues over secret 'b...             0   \n",
       "1  the 'roseanne' revival catches up to our thorn...             0   \n",
       "2  mom starting to fear son's web series closest ...             1   \n",
       "3  boehner just wants wife to listen, not come up...             1   \n",
       "4  j.k. rowling wishes snape happy birthday in th...             0   \n",
       "\n",
       "                                          clean_head           bow  \n",
       "0  [former, versace, store, clerk, sues, secret, ...  [0, 0, 0, 0]  \n",
       "1  [roseanne, revival, catches, thorny, political...  [0, 0, 0, 0]  \n",
       "2  [mom, starting, fear, sons, web, series, close...  [0, 0, 0, 0]  \n",
       "3  [boehner, wants, wife, listen, come, alternati...  [0, 0, 0, 0]  \n",
       "4  [jk, rowling, wishes, snape, happy, birthday, ...  [0, 0, 0, 0]  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def sentence_to_bow(sentence, vocab):\n",
    "    bow = [sentence.count(w) for w in vocab]\n",
    "    return bow\n",
    "\n",
    "vocab = ['trump', 'nation', 'area', 'onion']\n",
    "df['bow'] = df['clean_head'].apply(lambda x: sentence_to_bow(x, vocab))\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train and test\n",
    "\n",
    "Once we've created our features, we need to split out data into train and test datasets.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((23275, 4), (2587, 4), (23275,), (2587,))"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = np.array(list(df['bow']), dtype=np.float32)\n",
    "y = df['is_sarcastic'].to_numpy()\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1)\n",
    "\n",
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression\n",
    "\n",
    "Suppose we have a features $x$ with a target output $y$.\n",
    "\n",
    "For our use case $x$ could be a particular word, and $y$ is whether the headline is sarcastic or not.\n",
    "\n",
    "---\n",
    "\n",
    "In school you will (hopefully) have learned about *linear regression*,\n",
    "where the goal is to learn coefficients $a$ and $b$\n",
    "that minimize the error\n",
    "\n",
    "$err = \\sqrt {(y_* - y)^2}$\n",
    "\n",
    "where $y_* = ax + b$\n",
    "\n",
    "This is a good method when the $y_*$ are unbounded, \n",
    "but we need our outputs to be probabilities,\n",
    "so they have to lie in the closed interval $[0, 1]$.\n",
    "\n",
    "Exercise: Check that for any real-valued input $y_*, \\sigma(y_*)$ lies in $[0, 1]$.\n",
    "\n",
    "---\n",
    "\n",
    "We can achieve this with *logistic regression*.\n",
    "\n",
    "This is an adapation of linear regression where we push $y_*$ through a *logistic function*\n",
    "\n",
    "$\\sigma(y_*) = \\frac{1}{1 + e^{-y_*}}$\n",
    "\n",
    "---\n",
    "\n",
    "Above we only have one feature, but regression can be generalized to work for multiple features. \n",
    "\n",
    "We will be borrowing an implementation of logistic regression from Sklearn.\n",
    "\n",
    "It also has other classification models which you can explore [here](https://scikit-learn.org/stable/supervised_learning.html).\n",
    "\n",
    "This model gives us a baseline of about 60% accuracy on the test set.\n",
    "\n",
    "By changing the features you should be able to achieve over 90% accuracy.\n",
    "\n",
    "We believe in you!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy: 59%\n",
      "Test accuracy: 58%\n"
     ]
    }
   ],
   "source": [
    "def fit_lr(X_train, y_train):\n",
    "    # Train a logistic regression model\n",
    "    model = LogisticRegression()\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Get the accuracy of the model on the train and the test data\n",
    "    train_score = model.score(X_train, y_train)\n",
    "    test_score = model.score(X_test, y_test)\n",
    "\n",
    "    print(f'Train accuracy: {int(100*train_score)}%')\n",
    "    print(f'Test accuracy: {int(100*test_score)}%')\n",
    "    \n",
    "    return model\n",
    "\n",
    "model = fit_lr(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Alternative features\n",
    "\n",
    "Inside of using word counts, we can use the mean word embeddings of headlines as features.\n",
    "\n",
    "This gives us about 70% accuracy on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-12-10 14:35:33,932 [6611] INFO     gensim.utils: loading Word2VecKeyedVectors object from ./models/word2vec.model\n",
      "2020-12-10 14:35:40,065 [6611] INFO     gensim.utils: loading vectors from ./models/word2vec.model.vectors.npy with mmap=None\n",
      "2020-12-10 14:35:45,515 [6611] INFO     gensim.utils: setting ignored attribute vectors_norm to None\n",
      "2020-12-10 14:35:45,516 [6611] INFO     gensim.utils: loaded ./models/word2vec.model\n",
      "2020-12-10 14:35:49,077 [6611] INFO     gensim.models.keyedvectors: precomputing L2-norms of word weight vectors\n"
     ]
    }
   ],
   "source": [
    "w2vmodel = Word2VecKeyedVectors.load(\"./models/word2vec.model\")\n",
    "w2vmodel.init_sims(replace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mean_vec(head):\n",
    "    vecs = [w2vmodel[w] for w in head if w in w2vmodel]\n",
    "    \n",
    "    if vecs:\n",
    "        mean_vec = np.array(np.mean(vecs, axis=0), dtype=np.float32)\n",
    "    else:\n",
    "        mean_vec = np.zeros(300, dtype=np.float32)\n",
    "    \n",
    "    return mean_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['mean_vec'] = df['clean_head'].apply(lambda x: get_mean_vec(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(list(df['mean_vec']), dtype=np.float32)\n",
    "y = df['is_sarcastic'].to_numpy()\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy: 74%\n",
      "Test accuracy: 74%\n"
     ]
    }
   ],
   "source": [
    "model = fit_lr(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Debugging\n",
    "\n",
    "To improve our model we'll need to examine where it's going wrong.\n",
    "\n",
    "Let's have a look at some of the headlines where it's failing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Idx: 3\n",
      "Prediction: 1\n",
      "Actual: 0\n",
      "Headline: how to actually get a bartender's attention\n",
      "\n",
      "Idx: 12\n",
      "Prediction: 0\n",
      "Actual: 1\n",
      "Headline: albert pujols and the end to down syndrome bullying\n",
      "\n",
      "Idx: 13\n",
      "Prediction: 1\n",
      "Actual: 0\n",
      "Headline: rex tillerson supposedly shifted exxon mobil's climate position. except he really didn't.\n",
      "\n",
      "Idx: 17\n",
      "Prediction: 0\n",
      "Actual: 1\n",
      "Headline: area family awakes to find michelle obama tending backyard garden\n",
      "\n",
      "Idx: 22\n",
      "Prediction: 0\n",
      "Actual: 1\n",
      "Headline: who urges end to routine antibiotic use in farm animals to stem rise of superbugs\n",
      "\n",
      "Idx: 29\n",
      "Prediction: 0\n",
      "Actual: 1\n",
      "Headline: house bipartisanship throws up pitifully weak toxic chemicals control bill\n",
      "\n",
      "Idx: 30\n",
      "Prediction: 1\n",
      "Actual: 0\n",
      "Headline: report: bots now make up 22% of twitter executives\n",
      "\n",
      "Idx: 34\n",
      "Prediction: 1\n",
      "Actual: 0\n",
      "Headline: frustration with husband taken out on soap scum\n",
      "\n",
      "Idx: 35\n",
      "Prediction: 0\n",
      "Actual: 1\n",
      "Headline: white house probes kushner business loans after ethics questions\n",
      "\n",
      "Idx: 39\n",
      "Prediction: 0\n",
      "Actual: 1\n",
      "Headline: newly engaged couple receives incredible outpouring of insincerity from family, friends\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def debug_output(y_pred, y_test, df, n_samples=5):\n",
    "    \"\"\"\n",
    "    Debug the output of your model\n",
    "    \n",
    "    :param y_pred: np.ndarray[bool]\n",
    "                 : Predictions of the sarcasm of X_test\n",
    "    :param y_test: np.ndarray[bool]\n",
    "                 : The true sarcasm of X_test\n",
    "    :param df: pd.core.frame.DataFrame\n",
    "             : The sarcasm data\n",
    "    :param n_samples: int (default = 5)\n",
    "                    : The number of samples to debug\n",
    "    \"\"\"\n",
    "    n_train = len(df) - len(y_pred)\n",
    "    test_headlines = df['headline'].to_numpy()[n_train:]\n",
    "    \n",
    "    # Find the predictions which were wrong\n",
    "    failed_idx = np.where(y_pred != y_test)[0]\n",
    "    \n",
    "    # Display a sample of the headlines where our model failed\n",
    "    for idx in failed_idx[:n_samples]:\n",
    "        print(f'Idx: {idx}')\n",
    "        print(f'Prediction: {y_pred[idx]}')\n",
    "        print(f'Actual: {y_test[idx]}')\n",
    "        print(f'Headline: {test_headlines[idx]}')\n",
    "        print('')\n",
    "    \n",
    "y_pred = model.predict(X_test)\n",
    "debug_output(y_pred, y_test, df, n_samples=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Further debugging\n",
    "\n",
    "To improve our model it is important to examine how it's making predictions.\n",
    "We can do this by looking at the importance that it places on each word.\n",
    "\n",
    "If the coefficient is positive, the word is used mostly in sarcastic headlines.\n",
    "\n",
    "If the coefficient is negative, the word is used mostly in non-sarcastic headlines.\n",
    "\n",
    "---\n",
    "\n",
    "Could this be useful for detecting which features are important?\n",
    "\n",
    "Could this be useful for detecting overfitting?\n",
    "\n",
    "--- \n",
    "\n",
    "Note - This only works when using the bag-of-words features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "area: 3.89\n",
      "nation: 2.75\n",
      "onion: 2.35\n",
      "trump: -1.31\n"
     ]
    }
   ],
   "source": [
    "def print_important_words(coef, vocab, n_words=10):\n",
    "    \"\"\"\n",
    "    Print the most important words according to the model coefficients\n",
    "    \n",
    "    :param coef: list[float]\n",
    "               : The importance of each coefficient\n",
    "    :param vocab: list[str]\n",
    "                : The vocabulary corresponding to the coefficients\n",
    "    :param n_words: int (default = 10)\n",
    "                  : The number of top words to show\n",
    "    \"\"\"\n",
    "    # Put the coefficients in order from biggest magnitude to smallest magnitude\n",
    "    top_idx = np.argsort(-abs(coef))\n",
    "    \n",
    "    # Take the top `n_words` coefficients\n",
    "    top_idx = top_idx[:n_words]\n",
    "    \n",
    "    for i in top_idx:\n",
    "        print(f'{vocab[i]}: {coef[i]:.2f}')\n",
    "\n",
    "coef = model.coef_[0]\n",
    "print_important_words(coef, vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Headline examination\n",
    "\n",
    "If we're interested in a particular word, we can print the headlines that contain it.\n",
    "\n",
    "This will help us to select new features and gain a better understanding of the current features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label: 1\n",
      "Headline: son of edward r. murrow says father 'real dirtbag' compared to onion reporters\n",
      "\n",
      "Label: 1\n",
      "Headline: heroic police officer talks man down from edge of purchasing subway footlong sweet onion chicken teriyaki\n",
      "\n",
      "Label: 1\n",
      "Headline: the onion apologizes\n",
      "\n",
      "Label: 1\n",
      "Headline: obama, romney urge americans to purchase 'the onion book of known knowledge'\n",
      "\n",
      "Label: 0\n",
      "Headline: the onion is getting into the movie business\n",
      "\n",
      "Label: 1\n",
      "Headline: onion twitter password changed to onionman77\n",
      "\n",
      "Label: 1\n",
      "Headline: fabled burger king employee places single onion ring in everyone's fries\n",
      "\n",
      "Label: 1\n",
      "Headline: mother of slaying victim glad it was onion reporter who knocked on her door half an hour after funeral\n",
      "\n",
      "Label: 1\n",
      "Headline: whales beach selves in attempt to purchase 'the onion book of known knowledge'\n",
      "\n",
      "Label: 1\n",
      "Headline: 'arby's has been putting more onion bits on their buns,' reports man sinking into heavy depression\n",
      "\n",
      "Label: 1\n",
      "Headline: man regrets straying from sour cream and onion potato chips\n",
      "\n",
      "Sarcasm: 10\n",
      "Not sarcasm: 1\n"
     ]
    }
   ],
   "source": [
    "def print_headlines_with_word(df, word):\n",
    "    \"\"\"\n",
    "    Find the headlines which contain the given word\n",
    "    \n",
    "    :param df: pd.core.frame.DataFrame\n",
    "             : The sarcasm data\n",
    "    :param word: str\n",
    "               : The word of interest\n",
    "    \"\"\"\n",
    "    \n",
    "    sarcasm = 0\n",
    "    not_sarcasm = 0\n",
    "    \n",
    "    for idx, row in df.iterrows():\n",
    "        \n",
    "        # Check if the word is in the headline\n",
    "        if word in row['headline'].split(' '):\n",
    "            \n",
    "            print(f'Label: {row[\"is_sarcastic\"]}')\n",
    "            print(f'Headline: {row[\"headline\"]}\\n')\n",
    "            \n",
    "            if row['is_sarcastic']:\n",
    "                sarcasm += 1\n",
    "            else:\n",
    "                not_sarcasm += 1\n",
    "                \n",
    "    print(f'Sarcasm: {sarcasm}')\n",
    "    print(f'Not sarcasm: {not_sarcasm}')\n",
    "            \n",
    "print_headlines_with_word(df, 'onion')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
