{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hey there, welcome to your final challenge\n",
    "\n",
    "You're finally going to have a chance to apply the skills you've been learning on a real-life dataset.\n",
    "\n",
    "Your task is to predict if a given news headline is sarcastic or not.\n",
    "\n",
    "<img src=\"images/you_dont_say.jpg\" width=\"400\">\n",
    "\n",
    "--- \n",
    "\n",
    "A good way to think about how a machine might detect sarcasm is to try it yourself.\n",
    "Which of these headlines is sarcastic?\n",
    "\n",
    "* \"Thinking about the way you look all the time burns 5,000 calories an hour\"\n",
    "* \"Safeguarding the well-being of children\"\n",
    "\n",
    "How did you make your decision? Which features of the text gave it away?\n",
    "This is the thought process you will need to make a good model.\n",
    "\n",
    "--- \n",
    "\n",
    "Feel free to be creative and write your own code wherever you want!\n",
    "\n",
    "The provided functions are only there to help you if you get stuck :)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "[nltk_data] Downloading package stopwords to\n[nltk_data]     C:\\Users\\ollie\\AppData\\Roaming\\nltk_data...\n[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from gensim.models.keyedvectors import Word2VecKeyedVectors\n",
    "from nltk.corpus import stopwords\n",
    "import string\n",
    "import nltk\n",
    "nltk.download(\"stopwords\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Size of data: 15862\nSarcasm percentage: 43%\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                                        article_link  \\\n",
       "0  https://www.huffingtonpost.com/entry/versace-b...   \n",
       "1  https://www.huffingtonpost.com/entry/roseanne-...   \n",
       "2  https://local.theonion.com/mom-starting-to-fea...   \n",
       "3  https://politics.theonion.com/boehner-just-wan...   \n",
       "4  https://www.huffingtonpost.com/entry/jk-rowlin...   \n",
       "\n",
       "                                            headline  is_sarcastic  \n",
       "0  former versace store clerk sues over secret 'b...             0  \n",
       "1  the 'roseanne' revival catches up to our thorn...             0  \n",
       "2  mom starting to fear son's web series closest ...             1  \n",
       "3  boehner just wants wife to listen, not come up...             1  \n",
       "4  j.k. rowling wishes snape happy birthday in th...             0  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>article_link</th>\n      <th>headline</th>\n      <th>is_sarcastic</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>https://www.huffingtonpost.com/entry/versace-b...</td>\n      <td>former versace store clerk sues over secret 'b...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>https://www.huffingtonpost.com/entry/roseanne-...</td>\n      <td>the 'roseanne' revival catches up to our thorn...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>https://local.theonion.com/mom-starting-to-fea...</td>\n      <td>mom starting to fear son's web series closest ...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>https://politics.theonion.com/boehner-just-wan...</td>\n      <td>boehner just wants wife to listen, not come up...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>https://www.huffingtonpost.com/entry/jk-rowlin...</td>\n      <td>j.k. rowling wishes snape happy birthday in th...</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 2
    }
   ],
   "source": [
    "# Load the in the data from CSV\n",
    "fp = '../data/train_df.csv'\n",
    "df = pd.read_csv(fp)\n",
    "\n",
    "# Print the number of headlines that we're dealing with\n",
    "print(f'Size of data: {len(df)}')\n",
    "\n",
    "# Print the percentage of headlines that are sarcastic\n",
    "sarcasm_percentage = int(100 * sum(df['is_sarcastic']) / len(df))\n",
    "print(f'Sarcasm percentage: {sarcasm_percentage}%')\n",
    "\n",
    "# Show a sample of the data\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                                        article_link  \\\n",
       "0  https://www.huffingtonpost.com/entry/versace-b...   \n",
       "1  https://www.huffingtonpost.com/entry/roseanne-...   \n",
       "2  https://local.theonion.com/mom-starting-to-fea...   \n",
       "3  https://politics.theonion.com/boehner-just-wan...   \n",
       "4  https://www.huffingtonpost.com/entry/jk-rowlin...   \n",
       "\n",
       "                                            headline  is_sarcastic  \\\n",
       "0  former versace store clerk sues over secret 'b...             0   \n",
       "1  the 'roseanne' revival catches up to our thorn...             0   \n",
       "2  mom starting to fear son's web series closest ...             1   \n",
       "3  boehner just wants wife to listen, not come up...             1   \n",
       "4  j.k. rowling wishes snape happy birthday in th...             0   \n",
       "\n",
       "                                          clean_head  \n",
       "0  [former, versace, store, clerk, sues, secret, ...  \n",
       "1  [roseanne, revival, catches, thorny, political...  \n",
       "2  [mom, starting, fear, sons, web, series, close...  \n",
       "3  [boehner, wants, wife, listen, come, alternati...  \n",
       "4  [jk, rowling, wishes, snape, happy, birthday, ...  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>article_link</th>\n      <th>headline</th>\n      <th>is_sarcastic</th>\n      <th>clean_head</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>https://www.huffingtonpost.com/entry/versace-b...</td>\n      <td>former versace store clerk sues over secret 'b...</td>\n      <td>0</td>\n      <td>[former, versace, store, clerk, sues, secret, ...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>https://www.huffingtonpost.com/entry/roseanne-...</td>\n      <td>the 'roseanne' revival catches up to our thorn...</td>\n      <td>0</td>\n      <td>[roseanne, revival, catches, thorny, political...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>https://local.theonion.com/mom-starting-to-fea...</td>\n      <td>mom starting to fear son's web series closest ...</td>\n      <td>1</td>\n      <td>[mom, starting, fear, sons, web, series, close...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>https://politics.theonion.com/boehner-just-wan...</td>\n      <td>boehner just wants wife to listen, not come up...</td>\n      <td>1</td>\n      <td>[boehner, wants, wife, listen, come, alternati...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>https://www.huffingtonpost.com/entry/jk-rowlin...</td>\n      <td>j.k. rowling wishes snape happy birthday in th...</td>\n      <td>0</td>\n      <td>[jk, rowling, wishes, snape, happy, birthday, ...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "source": [
    "stop_words = stopwords.words('english')\n",
    "\n",
    "def basic_tokenizer(sentence):\n",
    "    out = sentence\n",
    "    for x in string.punctuation:\n",
    "        out = out.replace(x, '')\n",
    "    out = out.lower().split()\n",
    "    return out\n",
    "\n",
    "def remove_stopwords(sentence, stop_words):\n",
    "    return [word for word in sentence if word not in stop_words]\n",
    "\n",
    "def preprocess(sentence, stop_words):\n",
    "    clean_sentence = remove_stopwords(basic_tokenizer(sentence), stop_words)\n",
    "    return clean_sentence\n",
    "\n",
    "df['clean_head'] = df['headline'].apply(lambda x: preprocess(x, stop_words))\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Features\n",
    "\n",
    "The first step we have to take in a machine learning task is to create features.\n",
    "\n",
    "Below our features will be the counts of each word in the vocab in each sentence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                                        article_link  \\\n",
       "0  https://www.huffingtonpost.com/entry/versace-b...   \n",
       "1  https://www.huffingtonpost.com/entry/roseanne-...   \n",
       "2  https://local.theonion.com/mom-starting-to-fea...   \n",
       "3  https://politics.theonion.com/boehner-just-wan...   \n",
       "4  https://www.huffingtonpost.com/entry/jk-rowlin...   \n",
       "\n",
       "                                            headline  is_sarcastic  \\\n",
       "0  former versace store clerk sues over secret 'b...             0   \n",
       "1  the 'roseanne' revival catches up to our thorn...             0   \n",
       "2  mom starting to fear son's web series closest ...             1   \n",
       "3  boehner just wants wife to listen, not come up...             1   \n",
       "4  j.k. rowling wishes snape happy birthday in th...             0   \n",
       "\n",
       "                                          clean_head  \\\n",
       "0  [former, versace, store, clerk, sues, secret, ...   \n",
       "1  [roseanne, revival, catches, thorny, political...   \n",
       "2  [mom, starting, fear, sons, web, series, close...   \n",
       "3  [boehner, wants, wife, listen, come, alternati...   \n",
       "4  [jk, rowling, wishes, snape, happy, birthday, ...   \n",
       "\n",
       "                                                 bow  \n",
       "0  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, ...  \n",
       "1  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, ...  \n",
       "2  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "3  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "4  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>article_link</th>\n      <th>headline</th>\n      <th>is_sarcastic</th>\n      <th>clean_head</th>\n      <th>bow</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>https://www.huffingtonpost.com/entry/versace-b...</td>\n      <td>former versace store clerk sues over secret 'b...</td>\n      <td>0</td>\n      <td>[former, versace, store, clerk, sues, secret, ...</td>\n      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, ...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>https://www.huffingtonpost.com/entry/roseanne-...</td>\n      <td>the 'roseanne' revival catches up to our thorn...</td>\n      <td>0</td>\n      <td>[roseanne, revival, catches, thorny, political...</td>\n      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, ...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>https://local.theonion.com/mom-starting-to-fea...</td>\n      <td>mom starting to fear son's web series closest ...</td>\n      <td>1</td>\n      <td>[mom, starting, fear, sons, web, series, close...</td>\n      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>https://politics.theonion.com/boehner-just-wan...</td>\n      <td>boehner just wants wife to listen, not come up...</td>\n      <td>1</td>\n      <td>[boehner, wants, wife, listen, come, alternati...</td>\n      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>https://www.huffingtonpost.com/entry/jk-rowlin...</td>\n      <td>j.k. rowling wishes snape happy birthday in th...</td>\n      <td>0</td>\n      <td>[jk, rowling, wishes, snape, happy, birthday, ...</td>\n      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "def sentence_to_bow(sentence, vocab):\n",
    "    bow = [sentence.count(w) for w in vocab]\n",
    "    return bow\n",
    "\n",
    "#vocab = ['trump', 'nation', 'area', 'onion']\n",
    "vocab = []\n",
    "for item in df['clean_head']:\n",
    "    for word in item:\n",
    "        if word not in vocab:\n",
    "            vocab.append(word)\n",
    "df['bow'] = (df['clean_head'].apply(lambda x: sentence_to_bow(x, vocab)))\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "<ipython-input-5-96fbe33e6cfa>:2: DeprecationWarning: Call to deprecated `init_sims` (Use fill_norms() instead. See https://github.com/RaRe-Technologies/gensim/wiki/Migrating-from-Gensim-3.x-to-4).\n  w2vmodel.init_sims(replace=True)\n"
     ]
    }
   ],
   "source": [
    "w2vmodel = Word2VecKeyedVectors.load(\"./models/word2vec.model\")\n",
    "w2vmodel.init_sims(replace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train and test\n",
    "\n",
    "Once we've created our features, we need to split out data into train and test datasets.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      " vocab\n",
      "word clif not in vocab\n",
      "word clif not in vocab\n",
      "word hasnt not in vocab\n",
      "word aoki not in vocab\n",
      "word 12 not in vocab\n",
      "word 12 not in vocab\n",
      "word chaffetz not in vocab\n",
      "word antitrump not in vocab\n",
      "word blackrubberclad not in vocab\n",
      "word ryans not in vocab\n",
      "word worldweary not in vocab\n",
      "word 3ring not in vocab\n",
      "word romneys not in vocab\n",
      "word 60 not in vocab\n",
      "word heimlich not in vocab\n",
      "word ruffalo not in vocab\n",
      "word retrocrazed not in vocab\n",
      "word sciencefiction not in vocab\n",
      "word 20s not in vocab\n",
      "word it not in vocab\n",
      "word wasnt not in vocab\n",
      "word corbyn not in vocab\n",
      "word 10 not in vocab\n",
      "word 2000 not in vocab\n",
      "word freerange not in vocab\n",
      "word hmo not in vocab\n",
      "word stouffers not in vocab\n",
      "word eichner not in vocab\n",
      "word moines not in vocab\n",
      "word perate not in vocab\n",
      "word 60 not in vocab\n",
      "word 13 not in vocab\n",
      "word hemsworth not in vocab\n",
      "word instagram not in vocab\n",
      "word dobrev not in vocab\n",
      "word gingrich not in vocab\n",
      "word shouldnt not in vocab\n",
      "word kaepernick not in vocab\n",
      "word tripledecker not in vocab\n",
      "word didnt not in vocab\n",
      "word pinterest not in vocab\n",
      "word witherspoon not in vocab\n",
      "word 33 not in vocab\n",
      "word buildabear not in vocab\n",
      "word ewok not in vocab\n",
      "word 88 not in vocab\n",
      "word hb2 not in vocab\n",
      "word tpp not in vocab\n",
      "word 60 not in vocab\n",
      "word comey not in vocab\n",
      "word 360degree not in vocab\n",
      "word bannon not in vocab\n",
      "word megyn not in vocab\n",
      "word twelfthgrade not in vocab\n",
      "word twostep not in vocab\n",
      "word bugnado not in vocab\n",
      "word pistorius not in vocab\n",
      "word prowhite not in vocab\n",
      "word aint not in vocab\n",
      "word antinobody not in vocab\n",
      "word pirollo not in vocab\n",
      "word 43 not in vocab\n",
      "word maloney not in vocab\n",
      "word hasnt not in vocab\n",
      "word brokenin not in vocab\n",
      "word 911 not in vocab\n",
      "word 21st not in vocab\n",
      "word fatshaming not in vocab\n",
      "word datadriven not in vocab\n",
      "word bezos not in vocab\n",
      "word dennys not in vocab\n",
      "word billcosbycom not in vocab\n",
      "word melos not in vocab\n",
      "word 14 not in vocab\n",
      "word mcgregor not in vocab\n",
      "word airbnb not in vocab\n",
      "word jenner not in vocab\n",
      "word 40 not in vocab\n",
      "word 28 not in vocab\n",
      "word sager not in vocab\n",
      "word fastestshrinking not in vocab\n",
      "word 2016 not in vocab\n",
      "word africanamericans not in vocab\n",
      "word altman not in vocab\n",
      "word specialedition not in vocab\n",
      "word directorscut not in vocab\n",
      "word bratz not in vocab\n",
      "word panafrican not in vocab\n",
      "word equifax not in vocab\n",
      "word selfemployment not in vocab\n",
      "word reedus not in vocab\n",
      "word 96 not in vocab\n",
      "word instagram not in vocab\n",
      "word 15 not in vocab\n",
      "word 90 not in vocab\n",
      "word christies not in vocab\n",
      "word 40 not in vocab\n",
      "word visine not in vocab\n",
      "word 2018 not in vocab\n",
      "word merriamwebster not in vocab\n",
      "word 20 not in vocab\n",
      "word nyad not in vocab\n",
      "word lgbtq not in vocab\n",
      "word antonin not in vocab\n",
      "word scalias not in vocab\n",
      "word 835 not in vocab\n",
      "word instagram not in vocab\n",
      "word chinas not in vocab\n",
      "word potemkin not in vocab\n",
      "word flynn not in vocab\n",
      "word theatre not in vocab\n",
      "word zuckerbergs not in vocab\n",
      "word techfree not in vocab\n",
      "word odom not in vocab\n",
      "word bighair not in vocab\n",
      "word shortrange not in vocab\n",
      "word 91 not in vocab\n",
      "word raddatz not in vocab\n",
      "word mueller not in vocab\n",
      "word republicanauthored not in vocab\n",
      "word fisa not in vocab\n",
      "word 27 not in vocab\n",
      "word iowan not in vocab\n",
      "word knifewielding not in vocab\n",
      "word treatable—yet not in vocab\n",
      "word greasedup not in vocab\n",
      "word 3po not in vocab\n",
      "word dermer not in vocab\n",
      "word raisman not in vocab\n",
      "word isnt not in vocab\n",
      "word fakeawish not in vocab\n",
      "word nratv not in vocab\n",
      "word doesnt not in vocab\n",
      "word didnt not in vocab\n",
      "word 2018 not in vocab\n",
      "word brooklyns not in vocab\n",
      "word dennys not in vocab\n",
      "word 10 not in vocab\n",
      "word crazybeautiful not in vocab\n",
      "word omalley not in vocab\n",
      "word quincy not in vocab\n",
      "word pistorius not in vocab\n",
      "word mulan not in vocab\n",
      "word dunst not in vocab\n",
      "word chechen not in vocab\n",
      "word islams not in vocab\n",
      "word 125 not in vocab\n",
      "word nobannowall not in vocab\n",
      "word halfton not in vocab\n",
      "word 400 not in vocab\n",
      "word testdriven not in vocab\n",
      "word widereaching not in vocab\n",
      "word milosevic not in vocab\n",
      "word albanians not in vocab\n",
      "word huffpollster not in vocab\n",
      "word eastwood not in vocab\n",
      "word 10 not in vocab\n",
      "word stressfree not in vocab\n",
      "word hamiltoninspired not in vocab\n",
      "word dunham not in vocab\n",
      "word naderite not in vocab\n",
      "word unitedcom not in vocab\n",
      "word chicagos not in vocab\n",
      "word joaquin not in vocab\n",
      "word lebowski not in vocab\n",
      "word shouldnt not in vocab\n",
      "word bahai not in vocab\n",
      "word toiletpaper not in vocab\n",
      "word holocaustdenying not in vocab\n",
      "word centauri not in vocab\n",
      "word 1300 not in vocab\n",
      "word pekingese not in vocab\n",
      "word melania not in vocab\n",
      "word legoland not in vocab\n",
      "word floridas not in vocab\n",
      "word mustsee not in vocab\n",
      "word ryans not in vocab\n",
      "word 15 not in vocab\n",
      "word selfie not in vocab\n",
      "word romneys not in vocab\n",
      "word gillespies not in vocab\n",
      "word gummis not in vocab\n",
      "word shondaland not in vocab\n",
      "word homoji not in vocab\n",
      "word tooba not in vocab\n",
      "word marwat not in vocab\n",
      "word signarama not in vocab\n",
      "word dorian not in vocab\n",
      "word starks not in vocab\n",
      "word 1998 not in vocab\n",
      "word 99 not in vocab\n",
      "word 50 not in vocab\n",
      "word seaworld not in vocab\n",
      "word huffpost not in vocab\n",
      "word melanesian not in vocab\n",
      "word 50 not in vocab\n",
      "word 30 not in vocab\n",
      "word 1960s not in vocab\n",
      "word 20 not in vocab\n",
      "word 60 not in vocab\n",
      "word pornhub not in vocab\n",
      "word pornhub not in vocab\n",
      "word zimmerman not in vocab\n",
      "word 37 not in vocab\n",
      "word sherwinwilliams not in vocab\n",
      "word coyne not in vocab\n",
      "word marias not in vocab\n",
      "word huffpollster not in vocab\n",
      "word isnt not in vocab\n",
      "word 6000 not in vocab\n",
      "word hanukkah not in vocab\n",
      "word pssy not in vocab\n",
      "word nras not in vocab\n",
      "word 100 not in vocab\n",
      "word sandler not in vocab\n",
      "word devos not in vocab\n",
      "word printwearing not in vocab\n",
      "word minime not in vocab\n",
      "word 500disc not in vocab\n",
      "word rowlings not in vocab\n",
      "word weinstein not in vocab\n",
      "word hyland not in vocab\n",
      "word didnt not in vocab\n",
      "word goodell not in vocab\n",
      "word selfinflicted not in vocab\n",
      "word iamthegoldenstatekillercom not in vocab\n",
      "word benghazi not in vocab\n",
      "word prestateoftheunion not in vocab\n",
      "word lawler not in vocab\n",
      "word erdogans not in vocab\n",
      "word 10 not in vocab\n",
      "word 60 not in vocab\n",
      "word 19 not in vocab\n",
      "word 98 not in vocab\n",
      "word camaros not in vocab\n",
      "word us–cuba not in vocab\n",
      "word magicmarkered not in vocab\n",
      "word ricecake not in vocab\n",
      "word fiorina not in vocab\n",
      "word 2015 not in vocab\n",
      "word 2014 not in vocab\n",
      "word 53inch not in vocab\n",
      "word nielsens not in vocab\n",
      "word oneamonth not in vocab\n",
      "word antebellums not in vocab\n",
      "word meldonium not in vocab\n",
      "word russias not in vocab\n",
      "word microsft not in vocab\n",
      "word 21 not in vocab\n",
      "word berle not in vocab\n",
      "word atlantaarea not in vocab\n",
      "word bloomsday not in vocab\n",
      "word pompeii not in vocab\n",
      "word zimmermans not in vocab\n",
      "word trayvon not in vocab\n",
      "word cronyist not in vocab\n",
      "word 100story not in vocab\n",
      "word offthebackofthedefender not in vocab\n",
      "word buzzerbeater not in vocab\n",
      "word goodell not in vocab\n",
      "word 10 not in vocab\n",
      "word paine not in vocab\n",
      "word 80 not in vocab\n",
      "word hallburtons not in vocab\n",
      "word selftalk not in vocab\n",
      "word hortonstyle not in vocab\n",
      "word arpaio not in vocab\n",
      "word elmore not in vocab\n",
      "word 87 not in vocab\n",
      "word edtech not in vocab\n",
      "word 30th not in vocab\n",
      "word 300 not in vocab\n",
      "word wozniak not in vocab\n",
      "word cosby not in vocab\n",
      "word daviss not in vocab\n",
      "word 2014 not in vocab\n",
      "word kimye not in vocab\n",
      "word instagrams not in vocab\n",
      "word adeles not in vocab\n",
      "word 93yearold not in vocab\n",
      "word takei not in vocab\n",
      "word clarence not in vocab\n",
      "word franz not in vocab\n",
      "word gavrilo not in vocab\n",
      "word princip not in vocab\n",
      "word 50 not in vocab\n",
      "word rickman not in vocab\n",
      "word chrissy not in vocab\n",
      "word teigen not in vocab\n",
      "word 19 not in vocab\n",
      "word 1000000 not in vocab\n",
      "word kozols not in vocab\n",
      "word mustread not in vocab\n",
      "word 17 not in vocab\n",
      "word heyers not in vocab\n",
      "word whammys not in vocab\n",
      "word nras not in vocab\n",
      "word nra not in vocab\n",
      "word syrias not in vocab\n",
      "word clarissa not in vocab\n",
      "word clarissa not in vocab\n",
      "word colaflavored not in vocab\n",
      "word thones not in vocab\n",
      "word brexit not in vocab\n",
      "word nordstrom not in vocab\n",
      "word baucus not in vocab\n",
      "word ivanka not in vocab\n",
      "word secretarian not in vocab\n",
      "word fourplaying not in vocab\n",
      "word 102 not in vocab\n",
      "word hosteating not in vocab\n",
      "word 12 not in vocab\n",
      "word toughguy not in vocab\n",
      "word trumpzilla not in vocab\n",
      "word ivanka not in vocab\n",
      "word obrien not in vocab\n",
      "word comeys not in vocab\n",
      "word thors not in vocab\n",
      "word yellowstone not in vocab\n",
      "word 6month not in vocab\n",
      "word acadia not in vocab\n",
      "word truman not in vocab\n",
      "word uscverdugo not in vocab\n",
      "word 1950s not in vocab\n",
      "word fugoo not in vocab\n",
      "word doesnt not in vocab\n",
      "word gellar not in vocab\n",
      "word aguilera not in vocab\n",
      "word ventimiglia not in vocab\n",
      "word lowpaid not in vocab\n",
      "word devos not in vocab\n",
      "word 8yearold not in vocab\n",
      "word religionmade not in vocab\n",
      "word salesmans not in vocab\n",
      "word 16th not in vocab\n",
      "word nunberg not in vocab\n",
      "word mueller not in vocab\n",
      "word 2016 not in vocab\n",
      "word ariana not in vocab\n",
      "word turretmounted not in vocab\n",
      "word luigi not in vocab\n",
      "word fineo not in vocab\n",
      "word hutsell not in vocab\n",
      "word valerie not in vocab\n",
      "word 25000 not in vocab\n",
      "word cruella not in vocab\n",
      "word smallminded not in vocab\n",
      "word kendrick not in vocab\n",
      "word ebolastricken not in vocab\n",
      "word icymi not in vocab\n",
      "word fruitvale not in vocab\n",
      "word soloway not in vocab\n",
      "word bannon not in vocab\n",
      "word kesha not in vocab\n",
      "word 3minute not in vocab\n",
      "word grassley not in vocab\n",
      "word gops not in vocab\n",
      "word mccains not in vocab\n",
      "word sleeverollingup not in vocab\n",
      "word balvin not in vocab\n",
      "word falluja not in vocab\n",
      "word subtember not in vocab\n",
      "word 11 not in vocab\n",
      "word antitrump not in vocab\n",
      "word 2016 not in vocab\n",
      "word fetty not in vocab\n",
      "word moststreamed not in vocab\n",
      "word hamill not in vocab\n",
      "word wordforword not in vocab\n",
      "word mobydick not in vocab\n",
      "word gianforte not in vocab\n",
      "word 12 not in vocab\n",
      "word irvin not in vocab\n",
      "word yalom not in vocab\n",
      "word deray not in vocab\n",
      "word mckesson not in vocab\n",
      "word judys not in vocab\n",
      "word shouldnt not in vocab\n",
      "word wharton—wharton not in vocab\n",
      "word 140 not in vocab\n",
      "word herointown not in vocab\n",
      "word 4thlargest not in vocab\n",
      "word inbus not in vocab\n",
      "word 50 not in vocab\n",
      "word 2017 not in vocab\n",
      "word 16 not in vocab\n",
      "word pepperidge not in vocab\n",
      "word milanos not in vocab\n",
      "word dimon not in vocab\n",
      "word 41767 not in vocab\n",
      "word 11 not in vocab\n",
      "word maralago not in vocab\n",
      "word belgrades not in vocab\n",
      "word lgbtq not in vocab\n",
      "word antitrump not in vocab\n",
      "word 60000 not in vocab\n",
      "word mathison not in vocab\n",
      "word oscarnominated not in vocab\n",
      "word 65 not in vocab\n",
      "word dianne not in vocab\n",
      "word feinstein not in vocab\n",
      "word didnt not in vocab\n",
      "word alton not in vocab\n",
      "word didnt not in vocab\n",
      "word — not in vocab\n",
      "word rolie not in vocab\n",
      "word omalley not in vocab\n",
      "word 15 not in vocab\n",
      "word merkel not in vocab\n",
      "word g20 not in vocab\n",
      "word whatsapp not in vocab\n",
      "word brazils not in vocab\n",
      "word rouseffs not in vocab\n",
      "word arianna not in vocab\n",
      "word huffington not in vocab\n",
      "word 89 not in vocab\n",
      "word neardef not in vocab\n",
      "word 200 not in vocab\n",
      "word lubitzs not in vocab\n",
      "word drugrelated not in vocab\n",
      "word dutertes not in vocab\n",
      "word 23 not in vocab\n",
      "word elon not in vocab\n",
      "word israelgaza not in vocab\n",
      "word — not in vocab\n",
      "word disneys not in vocab\n",
      "word foodloving not in vocab\n",
      "word 1click not in vocab\n",
      "word parkinsons not in vocab\n",
      "word mccrazy not in vocab\n",
      "word millionsmarchsf not in vocab\n",
      "word stockphoto not in vocab\n",
      "word 90 not in vocab\n",
      "word solomons not in vocab\n",
      "word bannons not in vocab\n",
      "word buttigieg not in vocab\n",
      "word doesnt not in vocab\n",
      "word stonerturneddoctor not in vocab\n",
      "word 1969 not in vocab\n",
      "word rossini not in vocab\n",
      "word caramoor not in vocab\n",
      "word alton not in vocab\n",
      "word 40 not in vocab\n",
      "word sixthgrade not in vocab\n",
      "word 12 not in vocab\n",
      "word topsecret not in vocab\n",
      "word bobbi not in vocab\n",
      "word hermione not in vocab\n",
      "word granger not in vocab\n",
      "word wiig not in vocab\n",
      "word haders not in vocab\n",
      "word hitlers not in vocab\n",
      "word coppola not in vocab\n",
      "word 10 not in vocab\n",
      "word corden not in vocab\n",
      "word page–driven not in vocab\n",
      "word beyoncé not in vocab\n",
      "word 1914 not in vocab\n",
      "word orville not in vocab\n",
      "word redenbacher not in vocab\n",
      "word 70 not in vocab\n",
      "word devos not in vocab\n",
      "word elon not in vocab\n",
      "word hoffmans not in vocab\n",
      "word crimea not in vocab\n",
      "word 2012 not in vocab\n",
      "word theroux not in vocab\n",
      "word kalief not in vocab\n",
      "word browders not in vocab\n",
      "word witherspoons not in vocab\n",
      "word fomo not in vocab\n",
      "word 2004 not in vocab\n",
      "word pitchperfect not in vocab\n",
      "word 2017 not in vocab\n",
      "word 95 not in vocab\n",
      "word schumer not in vocab\n",
      "word haitians not in vocab\n",
      "word ragnarök not in vocab\n",
      "word portauprince not in vocab\n",
      "word 8yearolds not in vocab\n",
      "word lynda not in vocab\n",
      "word heffernans not in vocab\n",
      "word selfcompassion not in vocab\n",
      "word goingaway not in vocab\n",
      "word beyoncé not in vocab\n",
      "word kims not in vocab\n",
      "word lehrer not in vocab\n",
      "word 15 not in vocab\n",
      "word weinsteins not in vocab\n",
      "word jeeves not in vocab\n",
      "word showerin not in vocab\n",
      "word 2017 not in vocab\n",
      "word usain not in vocab\n",
      "word buzzfeed not in vocab\n",
      "word petraeus not in vocab\n",
      "word 90s not in vocab\n",
      "word kasich not in vocab\n",
      "word mccartney not in vocab\n",
      "word yoko not in vocab\n",
      "word 194 not in vocab\n",
      "word 2016 not in vocab\n",
      "word lateworking not in vocab\n",
      "word haegue not in vocab\n",
      "word yangs not in vocab\n",
      "word leeum not in vocab\n",
      "word gops not in vocab\n",
      "word bondinspired not in vocab\n",
      "word kushner not in vocab\n",
      "word wamu not in vocab\n",
      "word chaplev not in vocab\n",
      "word lowcalorie not in vocab\n",
      "word kaine not in vocab\n",
      "word 750000 not in vocab\n",
      "word gingrich not in vocab\n",
      "word doesnt not in vocab\n",
      "word nsfw not in vocab\n",
      "word 17 not in vocab\n",
      "word zimmerman not in vocab\n",
      "word neonazi not in vocab\n",
      "word livelys not in vocab\n",
      "word comey not in vocab\n",
      "word rupaul not in vocab\n",
      "word gugu not in vocab\n",
      "word huffpost not in vocab\n",
      "word 22 not in vocab\n",
      "word chewbacca not in vocab\n",
      "word ballscopying not in vocab\n",
      "word kiyoko not in vocab\n",
      "word lamontagne not in vocab\n",
      "word islamophobe not in vocab\n",
      "word chargeyouatwhim not in vocab\n",
      "word selfhelped not in vocab\n",
      "word chibok not in vocab\n",
      "word cbo not in vocab\n",
      "word merrick not in vocab\n",
      "word guillermo not in vocab\n",
      "word seaworld not in vocab\n",
      "word 15second not in vocab\n",
      "word 300year not in vocab\n",
      "word ncis not in vocab\n",
      "word highfat not in vocab\n",
      "word selfdescribed not in vocab\n",
      "word nuclearattack not in vocab\n",
      "word pruitt not in vocab\n",
      "word 10000 not in vocab\n",
      "word 2016 not in vocab\n",
      "word rouhani not in vocab\n",
      "word irans not in vocab\n",
      "word postnuclear not in vocab\n",
      "word 2015 not in vocab\n",
      "word 2016 not in vocab\n",
      "word fivedecade not in vocab\n",
      "word hasnt not in vocab\n",
      "word evancho not in vocab\n",
      "word listerine not in vocab\n",
      "word 72 not in vocab\n",
      "word emojis not in vocab\n",
      "word 21 not in vocab\n",
      "word huffpost not in vocab\n",
      "word mres not in vocab\n",
      "word alig not in vocab\n",
      "word japans not in vocab\n",
      "word 10000 not in vocab\n",
      "word shouldnt not in vocab\n",
      "word kimmels not in vocab\n",
      "word alton not in vocab\n",
      "word isnt not in vocab\n",
      "word monsanto not in vocab\n",
      "word 62 not in vocab\n",
      "word 2015 not in vocab\n",
      "word knobbyfaced not in vocab\n",
      "word sotomayor not in vocab\n",
      "word wkzntv not in vocab\n",
      "word huckabees not in vocab\n",
      "word benghazi not in vocab\n",
      "word paintstyle not in vocab\n",
      "word randalia not in vocab\n",
      "word bestival not in vocab\n",
      "word michiganborn not in vocab\n",
      "word aweism not in vocab\n",
      "word 5yearold not in vocab\n",
      "word antilgbtq not in vocab\n",
      "word 22 not in vocab\n",
      "word mund not in vocab\n",
      "word secondguessing not in vocab\n",
      "word 39 not in vocab\n",
      "word eisenhower not in vocab\n",
      "word reagans not in vocab\n",
      "word supercuts not in vocab\n",
      "word comey not in vocab\n",
      "word thatll not in vocab\n",
      "word kendrick not in vocab\n",
      "word sza not in vocab\n",
      "word 2016 not in vocab\n",
      "word spokesbeast not in vocab\n",
      "word chapo not in vocab\n",
      "word congolese not in vocab\n",
      "word canadas not in vocab\n",
      "word inuit not in vocab\n",
      "word cubas not in vocab\n",
      "word shouldnt not in vocab\n",
      "word netflixs not in vocab\n",
      "word kokopellied not in vocab\n",
      "word 13 not in vocab\n",
      "word ice–themed not in vocab\n",
      "word celinda not in vocab\n",
      "word sixyearold not in vocab\n",
      "word horsebackriding not in vocab\n",
      "word cruzjohn not in vocab\n",
      "word kasich not in vocab\n",
      "word 14 not in vocab\n",
      "word cosby not in vocab\n",
      "word – not in vocab\n",
      "word aereo not in vocab\n",
      "word merrick not in vocab\n",
      "word gorsuch not in vocab\n",
      "word kardashians not in vocab\n",
      "word kubrick not in vocab\n",
      "word doesnt not in vocab\n",
      "word unhrc not in vocab\n",
      "word dyllan not in vocab\n",
      "word murrays not in vocab\n",
      "word firstgrade not in vocab\n",
      "word 12yearold not in vocab\n",
      "word glamour not in vocab\n",
      "word adeles not in vocab\n",
      "word charmin not in vocab\n",
      "word debtfree not in vocab\n",
      "word whitfield not in vocab\n",
      "word milly not in vocab\n",
      "word abcs not in vocab\n",
      "word engel not in vocab\n",
      "word 21st not in vocab\n",
      "word 37325 not in vocab\n",
      "word 72nd not in vocab\n",
      "word reddi not in vocab\n",
      "word 14day not in vocab\n",
      "word 89 not in vocab\n",
      "word 10 not in vocab\n",
      "word tormund not in vocab\n",
      "word tgi not in vocab\n",
      "word 10 not in vocab\n",
      "word csection not in vocab\n",
      "word 85 not in vocab\n",
      "word betterpaying not in vocab\n",
      "word halfassed not in vocab\n",
      "word irma not in vocab\n",
      "word hazmatsuit not in vocab\n",
      "word 100000aday not in vocab\n",
      "word sixthgraders not in vocab\n",
      "word 911 not in vocab\n",
      "word halfbrother not in vocab\n",
      "word charlottesville not in vocab\n",
      "word watterson not in vocab\n",
      "word hobbes not in vocab\n",
      "word subminimum not in vocab\n",
      "word 6yearold not in vocab\n",
      "word 2018 not in vocab\n",
      "word oahus not in vocab\n",
      "word tantaros not in vocab\n",
      "word ailes not in vocab\n",
      "word g20 not in vocab\n",
      "word 12yearold not in vocab\n",
      "word beavan not in vocab\n",
      "word doesnt not in vocab\n",
      "word didnt not in vocab\n",
      "word 30millionyearold not in vocab\n",
      "word doesnt not in vocab\n",
      "word vladimir not in vocab\n",
      "word nunes not in vocab\n",
      "word fidel not in vocab\n",
      "word 21gun not in vocab\n",
      "word domenici not in vocab\n",
      "word budweiser not in vocab\n",
      "word 2018 not in vocab\n",
      "word kearney not in vocab\n",
      "word howie not in vocab\n",
      "word 44 not in vocab\n",
      "word chappelle not in vocab\n",
      "word chappelles not in vocab\n",
      "word 10 not in vocab\n",
      "word kermit not in vocab\n",
      "word shaggys not in vocab\n",
      "word 2000s not in vocab\n",
      "word wasnt not in vocab\n",
      "word magdalene not in vocab\n",
      "word 12 not in vocab\n",
      "word supporterbuilt not in vocab\n",
      "word lobbyistonlawmaker not in vocab\n",
      "word bidens not in vocab\n",
      "word 21 not in vocab\n",
      "word whiteonwhite not in vocab\n",
      "word charlottesville not in vocab\n",
      "word mandela not in vocab\n",
      "word spicer not in vocab\n",
      "word doesnt not in vocab\n",
      "word timbaland not in vocab\n",
      "word dekkers not in vocab\n",
      "word postballet not in vocab\n",
      "word fifthgrader not in vocab\n",
      "word isnt not in vocab\n",
      "word 2000 not in vocab\n",
      "word kourtney not in vocab\n",
      "word disick not in vocab\n",
      "word culturefocused not in vocab\n",
      "word ryans not in vocab\n",
      "word lapierre not in vocab\n",
      "word exxonmobil not in vocab\n",
      "word 300 not in vocab\n",
      "word 400 not in vocab\n",
      "word 17 not in vocab\n",
      "word doesnt not in vocab\n",
      "word princeinspired not in vocab\n",
      "word shouldnt not in vocab\n",
      "word 1939 not in vocab\n",
      "word markell not in vocab\n",
      "word 1928 not in vocab\n",
      "word michiganstyle not in vocab\n",
      "word sylvester not in vocab\n",
      "word stallone not in vocab\n",
      "word 400000 not in vocab\n",
      "word exwall not in vocab\n",
      "word mckinnons not in vocab\n",
      "word kellyanne not in vocab\n",
      "word duvernay not in vocab\n",
      "word tearyeyed not in vocab\n",
      "word kaine not in vocab\n",
      "word keillor not in vocab\n",
      "word exemployee not in vocab\n",
      "word roscoes not in vocab\n",
      "word 16m not in vocab\n",
      "word 2014 not in vocab\n",
      "word ulbrichtballet not in vocab\n",
      "word 2014 not in vocab\n",
      "word 20yearold not in vocab\n",
      "word 100000 not in vocab\n",
      "word acousticguitarwielding not in vocab\n",
      "word bidens not in vocab\n",
      "word jinping not in vocab\n",
      "word didnt not in vocab\n",
      "word 98 not in vocab\n",
      "word manicdepressive not in vocab\n",
      "word munsters not in vocab\n",
      "word womenonly not in vocab\n",
      "word saor not in vocab\n",
      "word – not in vocab\n",
      "word dapl not in vocab\n",
      "word shehulk not in vocab\n",
      "word tresspasser not in vocab\n",
      "word westworld not in vocab\n",
      "word neardeath not in vocab\n",
      "word timetraveling not in vocab\n",
      "word ansari not in vocab\n",
      "word snls not in vocab\n",
      "word twoparty not in vocab\n",
      "word prankcall not in vocab\n",
      "word isnt not in vocab\n",
      "word monique not in vocab\n",
      "word mailerdaemon not in vocab\n",
      "word 7hour not in vocab\n",
      "word 43 not in vocab\n",
      "word 1200 not in vocab\n",
      "word flynn not in vocab\n",
      "word dennys not in vocab\n",
      "word 16 not in vocab\n",
      "word zoroastrianism not in vocab\n",
      "word homepod not in vocab\n",
      "word kesha not in vocab\n",
      "word breyer not in vocab\n",
      "word qtip not in vocab\n",
      "word 2015 not in vocab\n",
      "word isnt not in vocab\n",
      "word arbys not in vocab\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                                        article_link  \\\n",
       "0  https://www.huffingtonpost.com/entry/versace-b...   \n",
       "1  https://www.huffingtonpost.com/entry/roseanne-...   \n",
       "2  https://local.theonion.com/mom-starting-to-fea...   \n",
       "3  https://politics.theonion.com/boehner-just-wan...   \n",
       "4  https://www.huffingtonpost.com/entry/jk-rowlin...   \n",
       "\n",
       "                                            headline  is_sarcastic  \\\n",
       "0  former versace store clerk sues over secret 'b...             0   \n",
       "1  the 'roseanne' revival catches up to our thorn...             0   \n",
       "2  mom starting to fear son's web series closest ...             1   \n",
       "3  boehner just wants wife to listen, not come up...             1   \n",
       "4  j.k. rowling wishes snape happy birthday in th...             0   \n",
       "\n",
       "                                          clean_head  \\\n",
       "0  [former, versace, store, clerk, sues, secret, ...   \n",
       "1  [roseanne, revival, catches, thorny, political...   \n",
       "2  [mom, starting, fear, sons, web, series, close...   \n",
       "3  [boehner, wants, wife, listen, come, alternati...   \n",
       "4  [jk, rowling, wishes, snape, happy, birthday, ...   \n",
       "\n",
       "                                                 bow  \\\n",
       "0  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, ...   \n",
       "1  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, ...   \n",
       "2  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "3  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "4  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "\n",
       "                                                vecs  \n",
       "0  [0.32401923555880785, 0.28006773302331567, -0....  \n",
       "1  [0.1960348472930491, 0.1813446283340454, -0.06...  \n",
       "2  [0.14253034256398678, -0.057082670740783215, 0...  \n",
       "3  [0.09356081765145063, -0.011456608772277832, 0...  \n",
       "4  [0.07492709212237969, 0.2086553107947111, 0.13...  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>article_link</th>\n      <th>headline</th>\n      <th>is_sarcastic</th>\n      <th>clean_head</th>\n      <th>bow</th>\n      <th>vecs</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>https://www.huffingtonpost.com/entry/versace-b...</td>\n      <td>former versace store clerk sues over secret 'b...</td>\n      <td>0</td>\n      <td>[former, versace, store, clerk, sues, secret, ...</td>\n      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, ...</td>\n      <td>[0.32401923555880785, 0.28006773302331567, -0....</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>https://www.huffingtonpost.com/entry/roseanne-...</td>\n      <td>the 'roseanne' revival catches up to our thorn...</td>\n      <td>0</td>\n      <td>[roseanne, revival, catches, thorny, political...</td>\n      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, ...</td>\n      <td>[0.1960348472930491, 0.1813446283340454, -0.06...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>https://local.theonion.com/mom-starting-to-fea...</td>\n      <td>mom starting to fear son's web series closest ...</td>\n      <td>1</td>\n      <td>[mom, starting, fear, sons, web, series, close...</td>\n      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n      <td>[0.14253034256398678, -0.057082670740783215, 0...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>https://politics.theonion.com/boehner-just-wan...</td>\n      <td>boehner just wants wife to listen, not come up...</td>\n      <td>1</td>\n      <td>[boehner, wants, wife, listen, come, alternati...</td>\n      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n      <td>[0.09356081765145063, -0.011456608772277832, 0...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>https://www.huffingtonpost.com/entry/jk-rowlin...</td>\n      <td>j.k. rowling wishes snape happy birthday in th...</td>\n      <td>0</td>\n      <td>[jk, rowling, wishes, snape, happy, birthday, ...</td>\n      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n      <td>[0.07492709212237969, 0.2086553107947111, 0.13...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "source": [
    "vecs = []\n",
    "for item in df['clean_head']:\n",
    "    total = [0]*300\n",
    "    for word in item:\n",
    "        try:\n",
    "            total += w2vmodel[word]\n",
    "        except:\n",
    "            print(\"word {} not in vocab\".format(word))\n",
    "    vecs.append((total))\n",
    "\n",
    "df['vecs'] = vecs\n",
    "df.head()\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      ", 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])]]\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "ValueError",
     "evalue": "setting an array element with a sequence.",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;31mTypeError\u001b[0m: only size-1 arrays can be converted to Python scalars",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-24-768740140ff9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'vecs'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'bow'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mlinear_regression\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\linear_model\\_base.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    516\u001b[0m         \u001b[0maccept_sparse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpositive\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m'csr'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'csc'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'coo'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    517\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 518\u001b[1;33m         X, y = self._validate_data(X, y, accept_sparse=accept_sparse,\n\u001b[0m\u001b[0;32m    519\u001b[0m                                    y_numeric=True, multi_output=True)\n\u001b[0;32m    520\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36m_validate_data\u001b[1;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[0;32m    431\u001b[0m                 \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mcheck_y_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    432\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 433\u001b[1;33m                 \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_X_y\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mcheck_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    434\u001b[0m             \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    435\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 63\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     64\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m             \u001b[1;31m# extra_args > 0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_X_y\u001b[1;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[0;32m    812\u001b[0m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"y cannot be None\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    813\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 814\u001b[1;33m     X = check_array(X, accept_sparse=accept_sparse,\n\u001b[0m\u001b[0;32m    815\u001b[0m                     \u001b[0maccept_large_sparse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maccept_large_sparse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    816\u001b[0m                     \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 63\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     64\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m             \u001b[1;31m# extra_args > 0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator)\u001b[0m\n\u001b[0;32m    614\u001b[0m                     \u001b[0marray\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcasting\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"unsafe\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    615\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 616\u001b[1;33m                     \u001b[0marray\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    617\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mComplexWarning\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mcomplex_warning\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    618\u001b[0m                 raise ValueError(\"Complex data not supported\\n\"\n",
      "\u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\numpy\\core\\_asarray.py\u001b[0m in \u001b[0;36masarray\u001b[1;34m(a, dtype, order, like)\u001b[0m\n\u001b[0;32m    100\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0m_asarray_with_like\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlike\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlike\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    101\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 102\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    103\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    104\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: setting an array element with a sequence."
     ]
    }
   ],
   "source": [
    "linear_regression = LinearRegression()\n",
    "y = df['is_sarcastic']\n",
    "x = list(np.array(df[['vecs','bow']]))\n",
    "print(x)\n",
    "linear_regression.fit(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = linear_regression.predict(x)\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "['bow', 'vecs']\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [2, 15862]",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-18-57ae9cbdd658>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'is_sarcastic'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_numpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[1;31m#X_train.shape, X_test.shape, y_train.shape, y_test.shape\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\model_selection\\_split.py\u001b[0m in \u001b[0;36mtrain_test_split\u001b[1;34m(test_size, train_size, random_state, shuffle, stratify, *arrays)\u001b[0m\n\u001b[0;32m   2170\u001b[0m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"At least one array required as input\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2171\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2172\u001b[1;33m     \u001b[0marrays\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mindexable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marrays\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2173\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2174\u001b[0m     \u001b[0mn_samples\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_num_samples\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mindexable\u001b[1;34m(*iterables)\u001b[0m\n\u001b[0;32m    297\u001b[0m     \"\"\"\n\u001b[0;32m    298\u001b[0m     \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0m_make_indexable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mX\u001b[0m \u001b[1;32min\u001b[0m \u001b[0miterables\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 299\u001b[1;33m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    300\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    301\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_consistent_length\u001b[1;34m(*arrays)\u001b[0m\n\u001b[0;32m    260\u001b[0m     \u001b[0muniques\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munique\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlengths\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    261\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 262\u001b[1;33m         raise ValueError(\"Found input variables with inconsistent numbers of\"\n\u001b[0m\u001b[0;32m    263\u001b[0m                          \" samples: %r\" % [int(l) for l in lengths])\n\u001b[0;32m    264\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [2, 15862]"
     ]
    }
   ],
   "source": [
    "#X = np.array(list(df['vecs']), dtype=np.float32)\n",
    "#temp = [[list(df['vecs'])],[[list(df['bow'])]]]\n",
    "\n",
    "X = list(df[[\"bow\",\"vecs\"]])\n",
    "print(X)\n",
    "y = df['is_sarcastic'].to_numpy()\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1)\n",
    "#X_train.shape, X_test.shape, y_train.shape, y_test.shape\n",
    "\n",
    "#print(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_1 = sm.OLS(y_train, X_train).fit()\n",
    "lr_1.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression\n",
    "\n",
    "Suppose we have a features $x$ with a target output $y$.\n",
    "\n",
    "For our use case $x$ could be a particular word, and $y$ is whether the headline is sarcastic or not.\n",
    "\n",
    "---\n",
    "\n",
    "In school you will (hopefully) have learned about *linear regression*,\n",
    "where the goal is to learn coefficients $a$ and $b$\n",
    "that minimize the error\n",
    "\n",
    "$err = \\sqrt {(y_* - y)^2}$\n",
    "\n",
    "where $y_* = ax + b$\n",
    "\n",
    "This is a good method when the $y_*$ are unbounded, \n",
    "but we need our outputs to be probabilities,\n",
    "so they have to lie in the closed interval $[0, 1]$.\n",
    "\n",
    "Exercise: Check that for any real-valued input $y_*, \\sigma(y_*)$ lies in $[0, 1]$.\n",
    "\n",
    "---\n",
    "\n",
    "We can achieve this with *logistic regression*.\n",
    "\n",
    "This is an adapation of linear regression where we push $y_*$ through a *logistic function*\n",
    "\n",
    "$\\sigma(y_*) = \\frac{1}{1 + e^{-y_*}}$\n",
    "\n",
    "---\n",
    "\n",
    "Above we only have one feature, but regression can be generalized to work for multiple features. \n",
    "\n",
    "We will be borrowing an implementation of logistic regression from Sklearn.\n",
    "\n",
    "It also has other classification models which you can explore [here](https://scikit-learn.org/stable/supervised_learning.html).\n",
    "\n",
    "This model gives us a baseline of about 60% accuracy on the test set.\n",
    "\n",
    "By changing the features you should be able to achieve over 90% accuracy.\n",
    "\n",
    "We believe in you!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "ValueError",
     "evalue": "setting an array element with a sequence.",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;31mTypeError\u001b[0m: float() argument must be a string or a number, not 'list'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-8b62d54da04b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfit_lr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-11-8b62d54da04b>\u001b[0m in \u001b[0;36mfit_lr\u001b[1;34m(X_train, y_train)\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[1;31m# Train a logistic regression model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mLogisticRegression\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m     \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m     \u001b[1;31m# Get the accuracy of the model on the train and the test data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[0mtrain_score\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m   1342\u001b[0m             \u001b[0m_dtype\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat64\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1343\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1344\u001b[1;33m         X, y = self._validate_data(X, y, accept_sparse='csr', dtype=_dtype,\n\u001b[0m\u001b[0;32m   1345\u001b[0m                                    \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"C\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1346\u001b[0m                                    accept_large_sparse=solver != 'liblinear')\n",
      "\u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36m_validate_data\u001b[1;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[0;32m    431\u001b[0m                 \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mcheck_y_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    432\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 433\u001b[1;33m                 \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_X_y\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mcheck_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    434\u001b[0m             \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    435\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 63\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     64\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m             \u001b[1;31m# extra_args > 0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_X_y\u001b[1;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[0;32m    812\u001b[0m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"y cannot be None\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    813\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 814\u001b[1;33m     X = check_array(X, accept_sparse=accept_sparse,\n\u001b[0m\u001b[0;32m    815\u001b[0m                     \u001b[0maccept_large_sparse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maccept_large_sparse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    816\u001b[0m                     \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 63\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     64\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m             \u001b[1;31m# extra_args > 0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator)\u001b[0m\n\u001b[0;32m    614\u001b[0m                     \u001b[0marray\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcasting\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"unsafe\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    615\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 616\u001b[1;33m                     \u001b[0marray\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    617\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mComplexWarning\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mcomplex_warning\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    618\u001b[0m                 raise ValueError(\"Complex data not supported\\n\"\n",
      "\u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\numpy\\core\\_asarray.py\u001b[0m in \u001b[0;36masarray\u001b[1;34m(a, dtype, order, like)\u001b[0m\n\u001b[0;32m    100\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0m_asarray_with_like\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlike\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlike\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    101\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 102\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    103\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    104\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m__array__\u001b[1;34m(self, dtype)\u001b[0m\n\u001b[0;32m   1897\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1898\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__array__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1899\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1900\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1901\u001b[0m     def __array_wrap__(\n",
      "\u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\numpy\\core\\_asarray.py\u001b[0m in \u001b[0;36masarray\u001b[1;34m(a, dtype, order, like)\u001b[0m\n\u001b[0;32m    100\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0m_asarray_with_like\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlike\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlike\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    101\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 102\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    103\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    104\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: setting an array element with a sequence."
     ]
    }
   ],
   "source": [
    "def fit_lr(X_train, y_train):\n",
    "    # Train a logistic regression model\n",
    "    model = LogisticRegression()\n",
    "    model.fit(X_train, y_train)\n",
    "    # Get the accuracy of the model on the train and the test data\n",
    "    train_score = model.score(X_train, y_train)\n",
    "    test_score = model.score(X_test, y_test)\n",
    "\n",
    "    print(f'Train accuracy: {int(100*train_score)}%')\n",
    "    print(f'Test accuracy: {int(100*test_score)}%') \n",
    "    \n",
    "    return model\n",
    "\n",
    "model = fit_lr(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Alternative features\n",
    "\n",
    "Inside of using word counts, we can use the mean word embeddings of headlines as features.\n",
    "\n",
    "This gives us about 70% accuracy on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "w2vmodel = Word2VecKeyedVectors.load(\"./models/word2vec.model\")\n",
    "w2vmodel.init_sims(replace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mean_vec(head):\n",
    "    vecs = [w2vmodel[w] for w in head if w in w2vmodel]\n",
    "    \n",
    "    if vecs:\n",
    "        mean_vec = np.array(np.mean(vecs, axis=0), dtype=np.float32)\n",
    "    else:\n",
    "        mean_vec = np.zeros(300, dtype=np.float32)\n",
    "    \n",
    "    return mean_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['mean_vec'] = df['clean_head'].apply(lambda x: get_mean_vec(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[[ 0.03240193  0.02800677 -0.01525985 ... -0.02224203  0.02556937\n   0.01908811]\n [ 0.02800498  0.02590637 -0.00986978 ... -0.00657245  0.01931108\n   0.04447164]\n [ 0.0158367  -0.00634252  0.01694649 ... -0.04116534  0.00284461\n   0.0050803 ]\n ...\n [ 0.04946033  0.04542911 -0.01374706 ... -0.05818217  0.01068554\n  -0.02426743]\n [ 0.02833284 -0.01973758 -0.02485151 ...  0.00610715  0.01327639\n  -0.01566681]\n [ 0.0231804   0.02762462  0.01079484 ... -0.03451134 -0.00932075\n  -0.00485594]]\n"
     ]
    }
   ],
   "source": [
    "X = np.array(list(df['mean_vec']), dtype=np.float32)\n",
    "y = df['is_sarcastic'].to_numpy()\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy: 74%\n",
      "Test accuracy: 74%\n"
     ]
    }
   ],
   "source": [
    "model = fit_lr(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Debugging\n",
    "\n",
    "To improve our model we'll need to examine where it's going wrong.\n",
    "\n",
    "Let's have a look at some of the headlines where it's failing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Idx: 1\nPrediction: 0\nActual: 1\nHeadline: man claims ex cares more about 'nonexistent' singing career than their daughter\n\nIdx: 2\nPrediction: 0\nActual: 1\nHeadline: feds give $43 million to fast track development of ebola vaccines\n\nIdx: 3\nPrediction: 0\nActual: 1\nHeadline: donald trump helped spread birtherism. now he can't stop it.\n\nIdx: 11\nPrediction: 0\nActual: 1\nHeadline: maine leading the way on government of, for and by the people\n\nIdx: 17\nPrediction: 0\nActual: 1\nHeadline: rare pokemon sparks massive stampede in taiwan\n\nIdx: 18\nPrediction: 0\nActual: 1\nHeadline: what's damaging about fat-shaming: the last acceptable form of bias\n\nIdx: 29\nPrediction: 1\nActual: 0\nHeadline: crisis and context for virgin galactic\n\nIdx: 39\nPrediction: 1\nActual: 0\nHeadline: want to sleep in 'the world's largest grave'? airbnb to the rescue\n\nIdx: 42\nPrediction: 0\nActual: 1\nHeadline: police say conditions too nippy to rescue missing hiker\n\nIdx: 50\nPrediction: 0\nActual: 1\nHeadline: donald trump's supreme court would overturn roe v. wade\n\n"
     ]
    }
   ],
   "source": [
    "def debug_output(y_pred, y_test, df, n_samples=5):\n",
    "    \"\"\"\n",
    "    Debug the output of your model\n",
    "    \n",
    "    :param y_pred: np.ndarray[bool]\n",
    "                 : Predictions of the sarcasm of X_test\n",
    "    :param y_test: np.ndarray[bool]\n",
    "                 : The true sarcasm of X_test\n",
    "    :param df: pd.core.frame.DataFrame\n",
    "             : The sarcasm data\n",
    "    :param n_samples: int (default = 5)\n",
    "                    : The number of samples to debug\n",
    "    \"\"\"\n",
    "    n_train = len(df) - len(y_pred)\n",
    "    test_headlines = df['headline'].to_numpy()[n_train:]\n",
    "    \n",
    "    # Find the predictions which were wrong\n",
    "    failed_idx = np.where(y_pred != y_test)[0]\n",
    "    \n",
    "    # Display a sample of the headlines where our model failed\n",
    "    for idx in failed_idx[:n_samples]:\n",
    "        print(f'Idx: {idx}')\n",
    "        print(f'Prediction: {y_pred[idx]}')\n",
    "        print(f'Actual: {y_test[idx]}')\n",
    "        print(f'Headline: {test_headlines[idx]}')\n",
    "        print('')\n",
    "    \n",
    "y_pred = model.predict(X_test)\n",
    "debug_output(y_pred, y_test, df, n_samples=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Further debugging\n",
    "\n",
    "To improve our model it is important to examine how it's making predictions.\n",
    "We can do this by looking at the importance that it places on each word.\n",
    "\n",
    "If the coefficient is positive, the word is used mostly in sarcastic headlines.\n",
    "\n",
    "If the coefficient is negative, the word is used mostly in non-sarcastic headlines.\n",
    "\n",
    "---\n",
    "\n",
    "Could this be useful for detecting which features are important?\n",
    "\n",
    "Could this be useful for detecting overfitting?\n",
    "\n",
    "--- \n",
    "\n",
    "Note - This only works when using the bag-of-words features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "output_type": "error",
     "ename": "IndexError",
     "evalue": "list index out of range",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-42-34c605c9872a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[0mcoef\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcoef_\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 22\u001b[1;33m \u001b[0mprint_important_words\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcoef\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvocab\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-42-34c605c9872a>\u001b[0m in \u001b[0;36mprint_important_words\u001b[1;34m(coef, vocab, n_words)\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtop_idx\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 19\u001b[1;33m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf'{vocab[i]}: {coef[i]:.2f}'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     20\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[0mcoef\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcoef_\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "def print_important_words(coef, vocab, n_words=10):\n",
    "    \"\"\"\n",
    "    Print the most important words according to the model coefficients\n",
    "    \n",
    "    :param coef: list[float]\n",
    "               : The importance of each coefficient\n",
    "    :param vocab: list[str]\n",
    "                : The vocabulary corresponding to the coefficients\n",
    "    :param n_words: int (default = 10)\n",
    "                  : The number of top words to show\n",
    "    \"\"\"\n",
    "    # Put the coefficients in order from biggest magnitude to smallest magnitude\n",
    "    top_idx = np.argsort(-abs(coef))\n",
    "    \n",
    "    # Take the top `n_words` coefficients\n",
    "    top_idx = top_idx[:n_words]\n",
    "    \n",
    "    for i in top_idx:\n",
    "        print(f'{vocab[i]}: {coef[i]:.2f}')\n",
    "\n",
    "coef = model.coef_[0]\n",
    "print_important_words(coef, vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Headline examination\n",
    "\n",
    "If we're interested in a particular word, we can print the headlines that contain it.\n",
    "\n",
    "This will help us to select new features and gain a better understanding of the current features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      " trump voters say they oppose key elements of gop obamacare replacement\n",
      "\n",
      "Label: 0\n",
      "Headline: sunday show hosts hit back on trump administration's lies\n",
      "\n",
      "Label: 0\n",
      "Headline: new ad hammers trump as too impulsive to allow near the nuclear button\n",
      "\n",
      "Label: 0\n",
      "Headline: donald trump vows to take travel ban to the supreme court\n",
      "\n",
      "Label: 1\n",
      "Headline: trump struck by beautiful vision of what america could be while looking out over seething, screaming arizona crowd\n",
      "\n",
      "Label: 1\n",
      "Headline: trump surrogate enjoying thrill of not knowing what she going to be defending minute to minute\n",
      "\n",
      "Label: 1\n",
      "Headline: ​report: all standing between trump and presidency is nation that made him billionaire celebrity\n",
      "\n",
      "Label: 0\n",
      "Headline: seth meyers has a not-so-subtle message for donald trump\n",
      "\n",
      "Label: 0\n",
      "Headline: trump replaces ice chief daniel ragsdale, appoints thomas homan\n",
      "\n",
      "Label: 0\n",
      "Headline: carly fiorina scores well on social media in face-off with trump\n",
      "\n",
      "Label: 0\n",
      "Headline: will the trump administration ever acknowledge climate change?\n",
      "\n",
      "Label: 0\n",
      "Headline: stephen colbert trolls donald trump jr. with murky 'russia week' intro\n",
      "\n",
      "Label: 0\n",
      "Headline: who could benefit from water rule change? trump and his golf courses\n",
      "\n",
      "Label: 0\n",
      "Headline: kathy griffin lawyers up to address 'bullying' from trump family\n",
      "\n",
      "Label: 0\n",
      "Headline: trump threw trans soldiers under the bus just to distract from gop health care grift\n",
      "\n",
      "Label: 0\n",
      "Headline: john legend tries in earnest to talk kanye west out of supporting trump\n",
      "\n",
      "Label: 0\n",
      "Headline: trump white house's revolving door of staff changes expected to continue in the new year\n",
      "\n",
      "Label: 1\n",
      "Headline: gop statisticians develop new branch of math to formulate scenarios in which trump doesn't win nomination\n",
      "\n",
      "Label: 1\n",
      "Headline: 'i promise to work tirelessly to achieve my campaign's goals,' threatens trump in terrifying address\n",
      "\n",
      "Label: 1\n",
      "Headline: trump spends entire classified national security briefing asking about ​egyptian ​mummies\n",
      "\n",
      "Label: 0\n",
      "Headline: trump attacks 'groveling' author of study showing no voter fraud\n",
      "\n",
      "Label: 0\n",
      "Headline: actually, donald trump told republicans all along how little he respects democracy\n",
      "\n",
      "Label: 0\n",
      "Headline: obamacare benefits plenty of people in states donald trump won\n",
      "\n",
      "Label: 0\n",
      "Headline: twitter users taunt rudy giuliani over new role on trump legal team\n",
      "\n",
      "Label: 1\n",
      "Headline: melania trump straightens husband's neck skin before walking out onto inauguration platform\n",
      "\n",
      "Label: 0\n",
      "Headline: new york attorney general conducting 'inquiry' into trump foundation\n",
      "\n",
      "Label: 0\n",
      "Headline: donald trump says some protesters probably deserved to get roughed up at his rallies\n",
      "\n",
      "Label: 1\n",
      "Headline: publicist worried kanye west's support of trump will damage his carefully crafted public image as a manic self-absorbed lunatic\n",
      "\n",
      "Label: 0\n",
      "Headline: report: dnc and clinton campaign funded research behind trump russia dossier\n",
      "\n",
      "Label: 0\n",
      "Headline: supporters defend kirsten gillibrand after trump delivers 'sexist smear'\n",
      "\n",
      "Label: 0\n",
      "Headline: j. k. rowling magically trolls donald trump for tweeting in the third person\n",
      "\n",
      "Label: 0\n",
      "Headline: how trump should approach u.s.-cuba policy\n",
      "\n",
      "Label: 0\n",
      "Headline: trump shames local 'mexican' judge involved in trump university lawsuit\n",
      "\n",
      "Label: 0\n",
      "Headline: donald trump to meet with editors of new yorker, vanity fair and vogue\n",
      "\n",
      "Label: 0\n",
      "Headline: trump filing shows he paid cohen, after cohen paid stormy\n",
      "\n",
      "Label: 0\n",
      "Headline: argentinian tv station trolls donald trump\n",
      "\n",
      "Label: 1\n",
      "Headline: donald trump jr. divorce leaves confused, heartbroken nation wondering why bad things happen to good people\n",
      "\n",
      "Label: 0\n",
      "Headline: twitter helped trump win, now it's starting to bury him\n",
      "\n",
      "Label: 0\n",
      "Headline: donald trump had a no good, very sad homecoming\n",
      "\n",
      "Label: 0\n",
      "Headline: gloria steinem warns that donald trump & state laws will endanger women's rights\n",
      "\n",
      "Label: 0\n",
      "Headline: trump officially declares opioid crisis an emergency 2 months after saying he would\n",
      "\n",
      "Label: 0\n",
      "Headline: trevor noah: donald trump selflessly embodies america's worst traits\n",
      "\n",
      "Label: 0\n",
      "Headline: cory booker pumps brakes on trump impeachment talk\n",
      "\n",
      "Label: 0\n",
      "Headline: donald trump calls hillary clinton 'the devil'\n",
      "\n",
      "Label: 0\n",
      "Headline: trump lawyer attended doj meeting on confidential fbi informant\n",
      "\n",
      "Label: 0\n",
      "Headline: trump populism has won the gop civil war? not a chance\n",
      "\n",
      "Label: 0\n",
      "Headline: astronaut eileen collins was supposed to endorse trump in her rnc speech, but didn't\n",
      "\n",
      "Label: 0\n",
      "Headline: bill maher trashes donald trump over his latest disgusting tweets\n",
      "\n",
      "Label: 0\n",
      "Headline: as trump kills daca, bannon's breitbart celebrates a major policy win\n",
      "\n",
      "Label: 0\n",
      "Headline: raucous town hall in utah blasts gop rep. chaffetz over trump\n",
      "\n",
      "Label: 0\n",
      "Headline: donald trump misspeaks, calls u.s. a company instead of a country\n",
      "\n",
      "Label: 0\n",
      "Headline: trump speaker warms up crowd with bizarre hillary-huma death fantasy\n",
      "\n",
      "Label: 1\n",
      "Headline: 'sometimes it feels like you're the only one who understands me,' whispers trump to white house roach infestation\n",
      "\n",
      "Label: 0\n",
      "Headline: trump team is mulling muslim registry and planning border wall, reported adviser says\n",
      "\n",
      "Label: 0\n",
      "Headline: donald trump gets brutally mocked over latest white house ousting\n",
      "\n",
      "Label: 1\n",
      "Headline: trump deploys national guard to press conference for standing ovation\n",
      "\n",
      "Label: 0\n",
      "Headline: sarah huckabee sanders suggests trump 'weighed in on' son's response to russia meeting\n",
      "\n",
      "Label: 0\n",
      "Headline: how we fooled donald trump into retweeting benito mussolini\n",
      "\n",
      "Label: 0\n",
      "Headline: senate dems want to know more as trump nominees cash out at their old jobs\n",
      "\n",
      "Label: 0\n",
      "Headline: chris christie says trump immigration order rollout was 'terrible'\n",
      "\n",
      "Label: 0\n",
      "Headline: consumer financial protection bureau could be defanged under donald trump\n",
      "\n",
      "Label: 1\n",
      "Headline: 'curses!' shouts fist-shaking meals on wheels ringleader as trump cuts off gravy train\n",
      "\n",
      "Label: 0\n",
      "Headline: all men are created equal. does president trump agree?\n",
      "\n",
      "Label: 0\n",
      "Headline: a new joint message from the kremlin and the trump administration\n",
      "\n",
      "Label: 0\n",
      "Headline: if trump praised other historic african-american figures like he did frederick douglass\n",
      "\n",
      "Label: 0\n",
      "Headline: trump court pick says he was joking when he compared gay marriage to marrying bacon\n",
      "\n",
      "Label: 0\n",
      "Headline: latino democrats arrested protesting trump on immigration\n",
      "\n",
      "Label: 0\n",
      "Headline: why bernie sanders and donald trump won the michigan primaries\n",
      "\n",
      "Label: 0\n",
      "Headline: trump didn't need a watergate to sink his ratings to nixonian levels\n",
      "\n",
      "Label: 0\n",
      "Headline: making sense of the trump russia morass\n",
      "\n",
      "Label: 1\n",
      "Headline: trump takes moment to thank all the fear in audience for making this night possible\n",
      "\n",
      "Label: 0\n",
      "Headline: donald trump was losing this election anyway\n",
      "\n",
      "Label: 0\n",
      "Headline: from atop the government, trump takes care of 'friends'\n",
      "\n",
      "Label: 0\n",
      "Headline: veterans are pissed at trump for not knowing how to spell marine corps\n",
      "\n",
      "Label: 0\n",
      "Headline: white house: trump didn't mean wiretapping when he accused obama of wiretapping\n",
      "\n",
      "Label: 0\n",
      "Headline: sam bee's show explains the gop tax plan 'in terms even a trump kid' can understand\n",
      "\n",
      "Label: 0\n",
      "Headline: eric trump 'liked' michelle wolf's blistering cracks about sarah huckabee sanders\n",
      "\n",
      "Label: 1\n",
      "Headline: ivana trump calls ex-husband to ask him what he did to her beautiful baby boy\n",
      "\n",
      "Label: 0\n",
      "Headline: donald trump to skip naacp convention\n",
      "\n",
      "Label: 0\n",
      "Headline: after peddling islamophobia, trump to give speech on islam while in saudi arabia\n",
      "\n",
      "Label: 0\n",
      "Headline: donald trump to begin fundraising 'right away'\n",
      "\n",
      "Label: 0\n",
      "Headline: obama refutes allegation that he wiretapped trump tower during campaign\n",
      "\n",
      "Label: 0\n",
      "Headline: trump brags that he won most of the women's vote in 2016. he didn't.\n",
      "\n",
      "Label: 0\n",
      "Headline: trump administration proposes massive expansion of offshore drilling\n",
      "\n",
      "Label: 0\n",
      "Headline: nationwide tax day marches demand donald trump release his tax returns\n",
      "\n",
      "Label: 0\n",
      "Headline: hillary clinton and donald trump did not shake hands before their second debate\n",
      "\n",
      "Label: 0\n",
      "Headline: will trump follow through on guns? he didn't do so on immigration.\n",
      "\n",
      "Label: 0\n",
      "Headline: what's it like waiting for donald trump to take office? a career federal employee spills the beans\n",
      "\n",
      "Label: 0\n",
      "Headline: while trump attacks colin kaepernick, the quarterback is donating to meals on wheels\n",
      "\n",
      "Label: 0\n",
      "Headline: depositions show donald trump as quick to exaggerate and insult\n",
      "\n",
      "Label: 0\n",
      "Headline: the bible has no place in modern american society: sobering lessons from donald trump and kim burrell\n",
      "\n",
      "Label: 0\n",
      "Headline: trump campaign ceo steve bannon failed to properly pay taxes for several years\n",
      "\n",
      "Label: 0\n",
      "Headline: trump fans the flames\n",
      "\n",
      "Label: 1\n",
      "Headline: trump promises government will continue to fund all essential mar-a-lago staff during shutdown\n",
      "\n",
      "Label: 0\n",
      "Headline: donald trump unveils tax plan that would lower taxes for millions\n",
      "\n",
      "Label: 0\n",
      "Headline: pennsylvania governor: dems can combat trump by getting things done\n",
      "\n",
      "Label: 1\n",
      "Headline: trump delivers anecdote about small business owner who isn't half the man he is\n",
      "\n",
      "Label: 0\n",
      "Headline: seth rogen takes down donald trump in donald trump jr.'s dms\n",
      "\n",
      "Label: 0\n",
      "Headline: read live updates from the confirmation hearings of several trump cabinet picks\n",
      "\n",
      "Label: 0\n",
      "Headline: most germans fear the effects of a trump election victory\n",
      "\n",
      "Label: 0\n",
      "Headline: ivanka trump and marco rubio's paid leave plan is a disaster for women\n",
      "\n",
      "Label: 0\n",
      "Headline: nato confronts turkey on human rights concerns after donald trump lets them slide\n",
      "\n",
      "Label: 1\n",
      "Headline: trump spends 10 minutes mistakenly addressing steve bannon's freshly shed exoskeleton\n",
      "\n",
      "Label: 0\n",
      "Headline: 'curb your enthusiasm' over rand paul's uneasy reaction to donald trump\n",
      "\n",
      "Label: 0\n",
      "Headline: nike ceo blasts trump executive order targeting muslims, refugees\n",
      "\n",
      "Label: 0\n",
      "Headline: here's why a nonprofit named for anne frank keeps attacking trump\n",
      "\n",
      "Label: 0\n",
      "Headline: why donald trump fears women\n",
      "\n",
      "Label: 0\n",
      "Headline: trump calls failed bid to repeal obamacare 'pretty impressive'\n",
      "\n",
      "Label: 0\n",
      "Headline: progressive challenger wants birmingham to be 'frontline resistance to trump policies'\n",
      "\n",
      "Label: 0\n",
      "Headline: ana navarro explains why it's hard for marginalized groups to give trump a chance\n",
      "\n",
      "Label: 0\n",
      "Headline: fake trump says meryl streep is 'no tara reid' in conan's spoof phone calls\n",
      "\n",
      "Label: 1\n",
      "Headline: john kelly struggles to maintain believable trump impression during phone calls with parkland survivors\n",
      "\n",
      "Label: 0\n",
      "Headline: donald trump has spent less than any other primary front-runner\n",
      "\n",
      "Label: 0\n",
      "Headline: heidi klum stops talking trump for 'box of lies' with jimmy fallon\n",
      "\n",
      "Label: 0\n",
      "Headline: univision anchor booed at commencement after speaking spanish, mentioning trump\n",
      "\n",
      "Label: 0\n",
      "Headline: donald trump opponents' path to victory is dark and full of terrors\n",
      "\n",
      "Label: 0\n",
      "Headline: surprise! the russian media just loves donald trump\n",
      "\n",
      "Label: 0\n",
      "Headline: from 'scandal' to 'house of cards,' political dramas are suffering in the trump era\n",
      "\n",
      "Label: 1\n",
      "Headline: naked eric trump runs through state dinner pursued by screaming au pair\n",
      "\n",
      "Label: 0\n",
      "Headline: trump praises saddam hussein again — this time for killing terrorists 'so good'\n",
      "\n",
      "Label: 0\n",
      "Headline: donald trump picks elaine chao to lead department of transportation\n",
      "\n",
      "Label: 0\n",
      "Headline: it's already looking like trump vs. clinton in this swing virginia county\n",
      "\n",
      "Label: 1\n",
      "Headline: aides trying to talk trump out of sending associates to break into watergate office complex\n",
      "\n",
      "Label: 0\n",
      "Headline: the stop trump movement got new life in ohio\n",
      "\n",
      "Label: 1\n",
      "Headline: trump vomits immediately after seeing everyday americans up close\n",
      "\n",
      "Label: 0\n",
      "Headline: john kerry issues dire warning on israeli settlements ahead of pro-settlement donald trump entering office\n",
      "\n",
      "Label: 0\n",
      "Headline: donald trump renews call for courts to reinstate travel ban after london incident\n",
      "\n",
      "Label: 0\n",
      "Headline: donald trump says his supporters should 'hit back' at protesters more often\n",
      "\n",
      "Label: 0\n",
      "Headline: donald trump is 'honoring' the outdoors with policies to ruin it\n",
      "\n",
      "Label: 0\n",
      "Headline: donald trump has a new conspiracy theory. this one involves google.\n",
      "\n",
      "Label: 0\n",
      "Headline: donald trump is terrible news for our food system\n",
      "\n",
      "Label: 0\n",
      "Headline: donald trump set to issue executive orders targeting trade deficit\n",
      "\n",
      "Label: 0\n",
      "Headline: white house lawyer insists trump isn't considering firing mueller\n",
      "\n",
      "Label: 0\n",
      "Headline: chaffetz, cummings seek answers from trump on his business' profits from foreign governments\n",
      "\n",
      "Label: 0\n",
      "Headline: the gop would probably have a better chance of winning without trump\n",
      "\n",
      "Label: 0\n",
      "Headline: trump told friends 'you all just got a lot richer' from tax bill: report\n",
      "\n",
      "Label: 0\n",
      "Headline: newt gingrich thinks nepotism laws shouldn't apply to trump administration\n",
      "\n",
      "Label: 0\n",
      "Headline: donald trump suggests colin kaepernick 'find a new country' after national anthem protest\n",
      "\n",
      "Label: 0\n",
      "Headline: trump administration axes funding for nasa system that monitors greenhouse gases\n",
      "\n",
      "Label: 0\n",
      "Headline: fox news ceo demands donald trump apologize for new megyn kelly attacks\n",
      "\n",
      "Label: 0\n",
      "Headline: donald trump and paul ryan meet in hopes of mending divided party\n",
      "\n",
      "Label: 0\n",
      "Headline: donald trump helped spread birtherism. now he can't stop it.\n",
      "\n",
      "Label: 0\n",
      "Headline: donald trump keeps saying things that would destroy any other presidential candidate\n",
      "\n",
      "Label: 0\n",
      "Headline: as trump and north korea hurl threats, hawaii prepares for a nuclear attack\n",
      "\n",
      "Label: 1\n",
      "Headline: trump administration refusing to disclose names of white house diamond elite members\n",
      "\n",
      "Label: 0\n",
      "Headline: 'isis truther' donald trump is like a lawyer's dumbest client ever, trevor noah says\n",
      "\n",
      "Label: 0\n",
      "Headline: hillary clinton hits trump administration for approach to lgbtq issues\n",
      "\n",
      "Label: 0\n",
      "Headline: trump supporters organize their own rallies across the country\n",
      "\n",
      "Label: 1\n",
      "Headline: rural working-class archbishops come out in droves to welcome trump to vatican\n",
      "\n",
      "Label: 0\n",
      "Headline: fbi has 'grave concerns' on republican-authored fisa memo trump wants released\n",
      "\n",
      "Label: 0\n",
      "Headline: thousands march in washington, d.c. heat to demand trump act on climate change\n",
      "\n",
      "Label: 0\n",
      "Headline: trump tells guam governor nuclear tensions will mean more tourism\n",
      "\n",
      "Label: 0\n",
      "Headline: that 'historic' middle-class tax cut trump promised? still just a promise.\n",
      "\n",
      "Label: 0\n",
      "Headline: huffpollster: voters remain very negative about donald trump and hillary clinton\n",
      "\n",
      "Label: 0\n",
      "Headline: fox news host: donald trump could get corporate sponsors for his wall\n",
      "\n",
      "Label: 1\n",
      "Headline: trump calms nerves before inaugural address by reminding himself he's the only person who actually exists\n",
      "\n",
      "Label: 0\n",
      "Headline: did melania trump really 'like' my tweet about her marriage?\n",
      "\n",
      "Label: 0\n",
      "Headline: undocumented student who posted viral tax form selfie asks trump for his receipts\n",
      "\n",
      "Label: 0\n",
      "Headline: woman alleges donald trump groped her at 1998 tennis tournament\n",
      "\n",
      "Label: 0\n",
      "Headline: no thank you, trump america\n",
      "\n",
      "Label: 0\n",
      "Headline: trump vows to kill 50 years of federal health and safety protections\n",
      "\n",
      "Label: 0\n",
      "Headline: stop hating trump voters\n",
      "\n",
      "Label: 1\n",
      "Headline: frustrated russian officials struggling to get any policies through dysfunctional trump administration\n",
      "\n",
      "Label: 0\n",
      "Headline: newspaper front pages usher in uncertainty of new trump era\n",
      "\n",
      "Label: 0\n",
      "Headline: trump says gulf states will pay for syrian safe zones. that's not the issue.\n",
      "\n",
      "Label: 0\n",
      "Headline: trump says roy moore should concede senate race to doug jones\n",
      "\n",
      "Label: 0\n",
      "Headline: trump rebuffs his opioid task force, declines to declare state of emergency\n",
      "\n",
      "Label: 0\n",
      "Headline: eminem goes after donald trump on new big sean track\n",
      "\n",
      "Label: 0\n",
      "Headline: usa today editorial board calls trump unfit to clean obama's toilets in scathing editorial\n",
      "\n",
      "Label: 0\n",
      "Headline: john mccain rips donald trump for pardoning joe arpaio\n",
      "\n",
      "Label: 1\n",
      "Headline: crowd shocked after unhinged trump dangles baby from truman balcony\n",
      "\n",
      "Label: 0\n",
      "Headline: former trump aide sam nunberg says mueller probe 'not a witch hunt'\n",
      "\n",
      "Label: 0\n",
      "Headline: trump says he thought being president would be easier than his old life\n",
      "\n",
      "Label: 0\n",
      "Headline: trump is so toxic that even members of his own party would rather vote hillary\n",
      "\n",
      "Label: 0\n",
      "Headline: kuwait may owe as much as $60,000 for trump hotel event in d.c.\n",
      "\n",
      "Label: 0\n",
      "Headline: angela merkel vows g20 won't bow to trump on climate change\n",
      "\n",
      "Label: 0\n",
      "Headline: friday's morning email: here's how trump is undermining obamacare\n",
      "\n",
      "Label: 0\n",
      "Headline: isla fisher thanks donald trump for showing that 'unqualified orange people can win things'\n",
      "\n",
      "Label: 0\n",
      "Headline: senate democrats already willing to work with trump administration\n",
      "\n",
      "Label: 0\n",
      "Headline: trump reaffirms his intention to order war crimes, then backs down [update]\n",
      "\n",
      "Label: 0\n",
      "Headline: trump again downplays steve bannon's white house role\n",
      "\n",
      "Label: 0\n",
      "Headline: donald trump voted least desirable neighbor of the year\n",
      "\n",
      "Label: 1\n",
      "Headline: staffers frantically trying to restore chaos to white house before trump returns from asia trip\n",
      "\n",
      "Label: 1\n",
      "Headline: jeff sessions spits in face of fbi interrogator trying to get him to turn on trump\n",
      "\n",
      "Label: 1\n",
      "Headline: trump blasts critics who judge neo-nazi groups by most extreme members\n",
      "\n",
      "Label: 0\n",
      "Headline: former counterterrorism official slams 'coward' trump over comey firing\n",
      "\n",
      "Label: 0\n",
      "Headline: new hampshire looking increasingly out of reach for donald trump\n",
      "\n",
      "Label: 1\n",
      "Headline: trump dismisses accusers as women\n",
      "\n",
      "Label: 0\n",
      "Headline: trump says terror attack will 'probably help' marine le pen in french elections\n",
      "\n",
      "Label: 0\n",
      "Headline: trump claims credit for shock dem win in pennsylvania\n",
      "\n",
      "Label: 0\n",
      "Headline: will smith says trump may force him to run for president\n",
      "\n",
      "Label: 0\n",
      "Headline: rep. john lewis: trump is not a 'legitimate president'\n",
      "\n",
      "Label: 0\n",
      "Headline: trump now claims 'illegal immigrants' are behind voter fraud\n",
      "\n",
      "Label: 0\n",
      "Headline: donald trump makes dubious claim about inauguration singer jackie evancho\n",
      "\n",
      "Label: 0\n",
      "Headline: huffpost hill - trump heads to louisiana, will distribute the classiest, absolute best mres\n",
      "\n",
      "Label: 0\n",
      "Headline: how the data world missed the boat on trump\n",
      "\n",
      "Label: 0\n",
      "Headline: trump supporter who made nazi salute speaks out\n",
      "\n",
      "Label: 0\n",
      "Headline: trump responds to supreme court abortion ruling\n",
      "\n",
      "Label: 0\n",
      "Headline: stormy daniels smirks when asked if she had affair with donald trump\n",
      "\n",
      "Label: 1\n",
      "Headline: trump sick and tired of mainstream media always trying to put his words into some sort of context\n",
      "\n",
      "Label: 1\n",
      "Headline: trump boys chasing wounded boar around white house\n",
      "\n",
      "Label: 1\n",
      "Headline: trump vows to leave a better afghanistan for nation's grandchildren to fight in\n",
      "\n",
      "Label: 1\n",
      "Headline: donald trump rift not what paul ryan needed in middle of 14-day cleanse\n",
      "\n",
      "Label: 0\n",
      "Headline: the rich will hashtag even more pricey scarves, if trump gets his way\n",
      "\n",
      "Label: 0\n",
      "Headline: trump ally sues qatar for hacking his email\n",
      "\n",
      "Label: 0\n",
      "Headline: on any given day we simply don't know what trump we'll be getting\n",
      "\n",
      "Label: 0\n",
      "Headline: trump supporter still sees obama taking his guns when he goes to sleep\n",
      "\n",
      "Label: 0\n",
      "Headline: trump again proves his claim about waiting for 'facts' after charlottesville was garbage\n",
      "\n",
      "Label: 0\n",
      "Headline: hillary clinton and donald trump are 'borne on the fm waves of the heart'\n",
      "\n",
      "Label: 0\n",
      "Headline: donald trump boosts the national enquirer as likely showdown with hillary clinton looms\n",
      "\n",
      "Label: 0\n",
      "Headline: no, donald trump isn't doing what al gore did in 2000\n",
      "\n",
      "Label: 0\n",
      "Headline: a brief history of paul ryan's dance of death with donald trump\n",
      "\n",
      "Label: 1\n",
      "Headline: trump complains entire personality rigged against him\n",
      "\n",
      "Label: 1\n",
      "Headline: senate intelligence committee confirms from testimony that donald trump jr. has no knowledge\n",
      "\n",
      "Label: 1\n",
      "Headline: acoustic-guitar-wielding trump tells congress 'this here's the story of america'\n",
      "\n",
      "Label: 0\n",
      "Headline: mexican economic minister prepared 'to talk to the devil' if trump wins\n",
      "\n",
      "Label: 0\n",
      "Headline: aclu sounds alarm over trump administration's 'threat' to free speech\n",
      "\n",
      "Label: 1\n",
      "Headline: john kelly explains to furious trump that gold star widow cannot be demoted to silver star widow\n",
      "\n",
      "Sarcasm: 120\n",
      "Not sarcasm: 579\n"
     ]
    }
   ],
   "source": [
    "def print_headlines_with_word(df, word):\n",
    "    \"\"\"\n",
    "    Find the headlines which contain the given word\n",
    "    \n",
    "    :param df: pd.core.frame.DataFrame\n",
    "             : The sarcasm data\n",
    "    :param word: str\n",
    "               : The word of interest\n",
    "    \"\"\"\n",
    "    \n",
    "    sarcasm = 0\n",
    "    not_sarcasm = 0\n",
    "    \n",
    "    for idx, row in df.iterrows():\n",
    "        \n",
    "        # Check if the word is in the headline\n",
    "        if word in row['headline'].split(' '):\n",
    "            \n",
    "            print(f'Label: {row[\"is_sarcastic\"]}')\n",
    "            print(f'Headline: {row[\"headline\"]}\\n')\n",
    "            \n",
    "            if row['is_sarcastic']:\n",
    "                sarcasm += 1\n",
    "            else:\n",
    "                not_sarcasm += 1\n",
    "                \n",
    "    print(f'Sarcasm: {sarcasm}')\n",
    "    print(f'Not sarcasm: {not_sarcasm}')\n",
    "            \n",
    "print_headlines_with_word(df, 'trump')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python394jvsc74a57bd0a62adc3fac08fca5a09019b156b47d4f5b526f4103a342ddc7e564d066f87881",
   "display_name": "Python 3.9.4 64-bit"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  },
  "metadata": {
   "interpreter": {
    "hash": "a62adc3fac08fca5a09019b156b47d4f5b526f4103a342ddc7e564d066f87881"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}